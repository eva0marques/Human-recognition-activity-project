{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>\n",
    "\n",
    "## Soizick Magon de la Giclais et Eva Marquès, 5GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance d'Activité Humaine](https://github.com/wikistat/Ateliers-Big-Data/5-HumanActivityRecognition) ([*HAR*](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>  \n",
    "##  Seconde partie:  apprentissage (profond) des signaux bruts  avec <a href=\"https://keras.io/\"><img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" style=\"max-width: 100px; display: inline\" alt=\"Keras\"/></a>\n",
    "\n",
    "Ce notebook présente la partie prediction de l'activité. Pour l'exploration, se référer au calepin afférent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthèse des résultats obtenus\n",
    "\n",
    "Les données utilisées dans cette partie n'ont plus été travaillées par la connaissance métier. Elles sont sous forme brute de signaux. De part leur format, il a été possible de tester de nouveaux outils comme la décomposition en base d'ondelettes afin d'améliorer au mieux les scores de prédiction. Le verdict final est plutôt satisfaisant car les meilleurs résultats de prévision égalent voire surpassent ceux des données métier. Voici les principaux résultats obtenus dans ce script. \n",
    "\n",
    "Nous avons utilisé deux types de données d'apprentissages : les signaux bruts et les coefficients des signaux dans les bases d'ondelettes de Haar. Pour les coefficients d'ondelettes, nous avons créé une fonction qui permet de choisir le niveau de décomposition gardé et/ou le niveau de seuillage des coefficients. \n",
    "\n",
    "Ainsi, en faisant varier ces types de données, nous avons essayé de choisir pour chaque méthode le format qui donne le meilleur score. Nous avons remarqué qu'il n'y a pas un format des données qui se démarque des autres : cela varie d'une méthode à une autre. \n",
    "\n",
    "Contrairement à l'apprentissage sur données métier, les méthodes linéaires n'ont pas été performantes. Les scores ne dépassent pas 60% de précision pour les données brutes, et encore moins pour les coefficients d'ondelettes. \n",
    "\n",
    "La SVM non linéaire augmente le score avec les signaux bruts, mais n'est pas encore satisfaisante (77%). Les méthodes d'aggrégation de modèle (RandomForest et boosting) donnent déjà de très bons résultats sur les données brutes (entre 84 et 89%). En base d'ondelettes, en faisant varier le niveau de décomposition et/ou le niveau de seuillage, on obtient des résultats meilleurs qu'avec les données brutes : les scores varient entre 89 et 94%, ce dernier score étant obtenu avec RandomForest optimisé, comme pour les données brutes, par validation croisée. \n",
    "\n",
    "Enfin, la dernière famille de méthodes explorées est celle des réseaux de neurones. La librairie Keras a été implémentée afin de créer des réseaux profonds manuellement, avec différents types de couches. De plus, elle a été codée de sorte à ce que les calculs puissent être faits de manière parallèlisée sur carte GPU, ce qui diminue considérablement le temps de calcul. \n",
    "\n",
    "Une difficulté d'utilisation des réseaux profonds provient de l'infinité de combinaisons de couches possibles. Pour l'instant, la théorie reste assez floue quant à ces choix. Dans ce projet, nous avons exploré le fonctionnement de quelques couches classiques telles que la couche Dense, Drop out (qui enlève aléatoirement un pourcentage de neurone à chaque époque), les couches de convolutions (utiles pour prendre en compte la spatialité ou la temporalité), la couche LSTM (rebouclage de la sortie prédente sur l'entrée afin d'avoir un suivi des résultats passés). \n",
    "\n",
    "Remarquons que les réseaux de neurones Keras peuvent prendre en entrée les données sous un format multidimensionnel. Dans notre cas, cette possibilité est intéressante car les unités statistiques étudiées sont en fait des courbes de 128 points. Malgré cette remarque, le MLP prenant en entrée les signaux concaténés obtient de meilleurs résultats que celui avec les données multidimensionnelles. \n",
    "\n",
    "Ces méthodes donnent de très bons résultats. Grâce à l'implémentation de la validation croisée de Monte Carlo que nous avons effectuée, il a été possible de comparer les performances sans surestimer de trois réseaux. Le meilleur résultat obtenu est de 96.2% avec un réseau convolutionnel 1D: nous arrivons à l'objectif d'égaliser la performance jadis obtenue sur les données métier. \n",
    "\n",
    "Le réseau avec couche LSTM est très long en temps de calcul, malgré la carte GPU. Par ailleurs, les résultats n'égalent pas les autres réseaux. \n",
    "\n",
    "Nous aurions pu essayer d'améliorer la prédiction en proposant de nouvelles combinaisons de couches. Nous aurions pu aussi décomposer chaque signal dans la base d'ondelettes et les faire entrer dans les réseaux multidimensionnels. \n",
    "\n",
    "A propos de la meilleure méthode trouvée dans ce script (réseau convolutionnel 1D), la matrice de confusion montre que les classes `sitting` vs `standing` et `walking upstairs` vs `walking downstairs` ont toujours du mal à être discriminées. \n",
    "\n",
    "\n",
    "Ce projet montre qu'il est possible, avec des algorithmes différents, d'obtenir des performances similaires sur les données brutes que sur les données métier : il est possible d\"économiser le travail préliminaire, au prix de ne pas avoir peur de tester une multitude de méthodes. La méthode miracle n'existe pas... pour l'instant ! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Introduction\n",
    "###  1.1 Contexte\n",
    "Les données sont issues de la communauté qui vise la reconnaissance d'activités humaines (*Human activity recognition, HAR*) à partir d’enregistrements, par exemple du gyroscope et de l'accéléromètre d'un smartphone.\n",
    "Voir à ce propos l'[article](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) relatant un colloque de 2013.  \n",
    "\n",
    "Les données publiques disponibles ont été acquises, décrites et analysées par [Anguita et al. (2013)](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf). Elles sont accessibles sur le [dépôt](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) de l'University California Irvine (UCI) consacré à l'apprentissage machine ainsi que sur le site *Kaggle*.\n",
    "\n",
    "L'archive contient les données brutes: accélérations en x, y, et z, chacun de 128 colonnes. D'autres fichiers en y soustrayant la gravité naturelle ainsi que les accélérations angulaires en x, y, et z, soit en tout 9 fichiers. Mais 6 utiles avec 6*128=768 mesures.\n",
    "\n",
    "Les méthodes d'apprentissage sont appliquées sur ces données brutes, sans calculs préliminaires de caractéristiques (*features*).\n",
    "\n",
    "### 1.2 Objectif\n",
    "Cette deuxième étape s'intéresse aux données brutes. Est-il possible d'économiser le travail préliminaire de définition des variables métier en utilisant, par exemple, les ressources de décompositions systématiques sur une base d'ondelette ou un algorihtme d'apprentissage profond?\n",
    "\n",
    "**Objectif** Faire aussi bien (96% de bien classés) qu'avec les variables métier.\n",
    "\n",
    "### 1.3 Travail à réaliser\n",
    "**Attention l'accès à un environnement *GPU* est très vivement conseillé voire indispensable.**\n",
    "- Modélisation, prévision de l'échantillon test par\n",
    "   - Régression logistique (`Scikit-learn`)\n",
    "   - Apprentissage profond en utilisant `Keras` \n",
    "       - MLP sur signaux \"applatis\"\n",
    "       - MLP sur signaux mutlidimensionelles\n",
    "       - LSTM\n",
    "       - 1D Convolution\n",
    "       - 2D Convolution\n",
    "   \n",
    "- Ajouter à ce calepin: \n",
    "    - Application des méthodes d'apprentissage classique ou non sur les coefficients des décompositions des signaux en ondelettes\n",
    "    - optimisation des paramètres des différentes méthodes.\n",
    "    - Améliorer l'architexture des réseaux?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Mise en place\n",
    "### 2.1 Librairies et initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#Utils Sklearn\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEEP LEARNING \n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "# for reproducibility\n",
    "# https://github.com/fchollet/keras/issues/2280\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras.models as km \n",
    "import keras.layers as kl \n",
    "import keras.layers.core as klc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### 2.2 Prise en charge des données\n",
    "#### Sources\n",
    "\n",
    "Les données sont celles originales du dépôt de l'[UCI](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Elle peuvent être téléchargées en cliquant [ici](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip).\n",
    "\n",
    "Elles contiennent deux jeux de dimensions différentes, chacun partagé en apprentissage et test.\n",
    "\n",
    "1. Multidimensionel: un individus est constitué de 9 Séries Temporelles de *dimensions* $(N, 128, 9)$\n",
    "2. Unidimensionnel: Les 9 Séries Temporelles sont concaténées pour constituer un vecteur de 128x9 = 1152 variables de *dimensions* $(N, 1152)$\n",
    "        \n",
    "Deux objets différents sont construits pour définir la variable $Y$ réponse car les librairies `Scikit-learn` et `Keras` prennent en compte des structures différentes: \n",
    "    \n",
    "1. `Scikit-Learn`  Un vecteur de dimension $(N, 1)$ avec, pour chaque individu le numéro du label de l'activité de 0 à 5.\n",
    "2. `Keras` Une matrice de dimension $(N, 6)$ des indicatrices (0 ou 1) des modalités de $Y$.\n",
    "\n",
    "#### Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR_UCI = './../data_har'\n",
    "\n",
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\", \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]\n",
    "\n",
    "def my_read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "def load_signal(data_dir, subset, signal):\n",
    "    filename = f'{data_dir}/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "    x = my_read_csv(filename).as_matrix()\n",
    "    return x \n",
    "\n",
    "def load_signals(data_dir, subset, flatten = False):\n",
    "    signals_data = []\n",
    "    for signal in SIGNALS:\n",
    "        signals_data.append(load_signal(data_dir, subset, signal)) \n",
    "    \n",
    "    if flatten :\n",
    "        X = np.hstack(signals_data)\n",
    "    else:\n",
    "        X = np.transpose(signals_data, (1, 2, 0))\n",
    "        \n",
    "    return X \n",
    "\n",
    "def load_y(data_dir, subset, dummies = False):\n",
    "    filename = f'{data_dir}/{subset}/y_{subset}.txt'\n",
    "    y = my_read_csv(filename)[0]\n",
    "    \n",
    "    \n",
    "    if dummies:\n",
    "        Y = pd.get_dummies(y).as_matrix()\n",
    "    else:\n",
    "        Y = y.as_matrix()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Multidimensional Data\n",
    "X_train, X_test = load_signals(DATADIR_UCI, 'train'), load_signals(DATADIR_UCI, 'test')\n",
    "# Flattened Data\n",
    "X_train_flatten, X_test_flatten = load_signals(DATADIR_UCI, 'train', flatten=True), load_signals(DATADIR_UCI, 'test', flatten=True)\n",
    "\n",
    "# Label Y\n",
    "Y_train_label, Y_test_label = load_y(DATADIR_UCI, 'train', dummies = False), load_y(DATADIR_UCI, 'test', dummies = False)\n",
    "#Dummies Y (For Keras)\n",
    "Y_train_dummies, Y_test_dummies = load_y(DATADIR_UCI, 'train', dummies = True), load_y(DATADIR_UCI, 'test', dummies = True)\n",
    "\n",
    "N_train = X_train.shape[0]\n",
    "N_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension\n",
      "Données Multidimensionelles, : (7352, 128, 9)\n",
      "Données Unimensionelles, : (7352, 1152)\n",
      "Vecteur réponse (scikit-learn) : (7352,)\n",
      "Matrice réponse(Keras) : (7352, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension\")\n",
    "print(\"Données Multidimensionelles, : \" + str(X_train.shape))\n",
    "print(\"Données Unimensionelles, : \" + str(X_train_flatten.shape))\n",
    "print(\"Vecteur réponse (scikit-learn) : \" + str(Y_train_label.shape))\n",
    "print(\"Matrice réponse(Keras) : \" + str(Y_train_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"WALKING\",\"WALKING UPSTAIRS\",\"WALKING DOWNSTAIRS\",\"SITTING\",\"STANDING\",\"LAYING\"]\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "\n",
    "def my_confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Décomposition en bases d'ondelettes (Haar)\n",
    "\n",
    "On garde seulement le niveau de décomposition le plus fin.\n",
    "\n",
    "Nous avons choisi le niveau 10 comme niveau le plus fin car $2^{10} = 1024$ or nous avons $1152$ variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "from statsmodels.robust import mad\n",
    "import sklearn.decomposition as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wavelet_transformation()` : Fonction qui décompose en bases d'ondelettes \n",
    "\n",
    "`level` = niveau de décomposition max gardé (sauf pour le niveau 10 où on ne garde que le plus fin)  \n",
    "\n",
    "`threshold` = seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf = \"haar\"\n",
    "def wavelet_transformation(X,level=10,threshold=4):\n",
    "    Coeff = []\n",
    "    TCoeff = []\n",
    "    for x in X:\n",
    "        #Apply wabvelet decomposition\n",
    "        coeffs = pywt.wavedec(x,wf,level=level)\n",
    "        if level==10:\n",
    "            Coeff.append(coeffs[-1])\n",
    "        else:\n",
    "            coeffs_flatten = np.hstack(coeffs[1:level])\n",
    "            Coeff.append(coeffs_flatten)\n",
    "        # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "        sigma = mad(coeffs[-1])\n",
    "        uthresh = sigma*np.sqrt(2*np.log(128*9))\n",
    "        # Apply Threshold on 'threshold' fist level\n",
    "        coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=threshold-1 else c for i,c in enumerate(coeffs[::-1])]\n",
    "        coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "        TCoeff.append(coeffs_thresh_flatten)\n",
    "    return np.array(TCoeff),np.array(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 576) (7352, 1155)\n",
      "4234724 1703713\n"
     ]
    }
   ],
   "source": [
    "TCoeff_train,Coeff_train=wavelet_transformation(X_train_flatten)\n",
    "print(Coeff_train.shape, TCoeff_train.shape)\n",
    "print(np.sum(Coeff_train!=0), np.sum(TCoeff_train!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 576) (2947, 1155)\n",
      "1697463 691722\n"
     ]
    }
   ],
   "source": [
    "TCoeff_test,Coeff_test=wavelet_transformation(X_test_flatten)\n",
    "print(Coeff_test.shape, TCoeff_test.shape)\n",
    "print(np.sum(Coeff_test!=0), np.sum(TCoeff_test!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Apprentissage des signaux uni-dimensionnels\n",
    "\n",
    "La base d'apprentissage est de dimension (`N_train`, 1152)\n",
    "\n",
    "### 3.1 METHODES LINEAIRES - DONNEES BRUTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression Logistique\n",
    "\n",
    "La Régression Logistique est une des méthodes conduisant aux meilleurs résultats sur les variables métier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      " Score With Logistic Regression on Inertial Signals = 57.45, \n",
      " Learning time = 28.37 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>120</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>74</td>\n",
       "      <td>218</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>92</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>397</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>131</td>\n",
       "      <td>92</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 120                63                  97        0   \n",
       "WALKING UPSTAIRS         74               218                  56       23   \n",
       "WALKING DOWNSTAIRS       92                66                 103        1   \n",
       "SITTING                  79                32                  58      397   \n",
       "STANDING                131                92                 106       70   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    1       0  \n",
       "WALKING UPSTAIRS          72      27  \n",
       "WALKING DOWNSTAIRS         2       0  \n",
       "SITTING                  112       0  \n",
       "STANDING                 345       0  \n",
       "LAYING                     0     510  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_lr = lm.LogisticRegression(verbose=1)\n",
    "model_lr.fit(X_train_flatten, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lr.score(X_test_flatten, Y_test_label)\n",
    "print(\"\\n Score With Logistic Regression on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lr_prediction_label = model_lr.predict(X_test_flatten)\n",
    "metadata_lr = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lr_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de la performance?  \n",
    "La performance de la régression logistique sur les données brutes n'a rien à envier aux performances obtenues sur les données métier. Il y a beaucoup de confusions, même entre les classes actives et passives qui étaient plus facile à discriminer avec les données métier. On remarque cependant que la classe `laying` est bien discriminée par rapport aux autres. \n",
    "\n",
    "### Analyse Discriminante Linéaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score With Linear Discriminant Analysis on Inertial Signals = 58.84, \n",
      " Learning time = 1.15 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>132</td>\n",
       "      <td>93</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>74</td>\n",
       "      <td>146</td>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>117</td>\n",
       "      <td>69</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>313</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>158</td>\n",
       "      <td>140</td>\n",
       "      <td>117</td>\n",
       "      <td>153</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 132                93                 114        0   \n",
       "WALKING UPSTAIRS         74               146                  58       23   \n",
       "WALKING DOWNSTAIRS      117                69                 113        2   \n",
       "SITTING                  15                23                  18      313   \n",
       "STANDING                158               140                 117      153   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    4       0  \n",
       "WALKING UPSTAIRS           6       0  \n",
       "WALKING DOWNSTAIRS         3       0  \n",
       "SITTING                   26       0  \n",
       "STANDING                 493       0  \n",
       "LAYING                     0     537  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_lda=model_lda.fit(X_train_flatten, Y_train_label)\n",
    "score = model_lda.score(X_test_flatten, Y_test_label)\n",
    "ypred = model_lda.predict(X_test_flatten)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"\\n Score With Linear Discriminant Analysis on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lda_prediction_label = model_lda.predict(X_test_flatten)\n",
    "metadata_lda = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lda_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 METHODES LINEAIRES - COEFFICIENTS D'ONDELETTES\n",
    "\n",
    "### Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TCoeff_train,Coeff_train=wavelet_transformation(X_train_flatten,4)\n",
    "TCoeff_test,Coeff_test=wavelet_transformation(X_test_flatten,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      " Score With Logistic Regression on Inertial Signals (Haar)= 31.52, \n",
      " Learning time = 9.03 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>91</td>\n",
       "      <td>118</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>39</td>\n",
       "      <td>75</td>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>396</td>\n",
       "      <td>417</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 128                88                 103        2   \n",
       "WALKING UPSTAIRS         91               118                  89        1   \n",
       "WALKING DOWNSTAIRS      108                95                 111        1   \n",
       "SITTING                  14                15                   9       16   \n",
       "STANDING                 69                68                  39       75   \n",
       "LAYING                   86                87                  69      396   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    5       2  \n",
       "WALKING UPSTAIRS           0       0  \n",
       "WALKING DOWNSTAIRS         5       0  \n",
       "SITTING                    7       0  \n",
       "STANDING                  98      77  \n",
       "LAYING                   417     458  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_lr_haar = lm.LogisticRegression(verbose=1)\n",
    "model_lr_haar.fit(Coeff_train, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lr_haar.score(Coeff_test, Y_test_label)\n",
    "print(\"\\n Score With Logistic Regression on Inertial Signals (Haar)= %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lr_haar_prediction_label = model_lr_haar.predict(Coeff_test)\n",
    "metadata_lr_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lr_haar_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Discriminante Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score With Linear Disciminant Analysis on Inertial Signals (Haar) = 34.14, \n",
      " Learning time = 0.47 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>84</td>\n",
       "      <td>127</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>101</td>\n",
       "      <td>79</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>360</td>\n",
       "      <td>387</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>59</td>\n",
       "      <td>107</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 150                73                 100        2   \n",
       "WALKING UPSTAIRS         84               127                  59        7   \n",
       "WALKING DOWNSTAIRS      101                79                 112        2   \n",
       "SITTING                  40                29                  26       54   \n",
       "STANDING                 62                56                  67      360   \n",
       "LAYING                   59               107                  56       66   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    3       0  \n",
       "WALKING UPSTAIRS           3       5  \n",
       "WALKING DOWNSTAIRS         4       0  \n",
       "SITTING                   55      25  \n",
       "STANDING                 387     331  \n",
       "LAYING                    80     176  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_lda_haar = LinearDiscriminantAnalysis()\n",
    "model_lda_haar.fit(Coeff_train, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lda_haar.score(Coeff_test, Y_test_label)\n",
    "print(\"\\n Score With Linear Disciminant Analysis on Inertial Signals (Haar) = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lda_haar_prediction_label = model_lda_haar.predict(Coeff_test)\n",
    "metadata_lda_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lda_haar_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SVM, RF, GBM - DONNEES BRUTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "Score With Linear SVC on Inertial Signals = 56.40, \n",
      " Learning time = 60.52 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>125</td>\n",
       "      <td>81</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>70</td>\n",
       "      <td>204</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>74</td>\n",
       "      <td>54</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>92</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>395</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>135</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>71</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 125                81                 116        0   \n",
       "WALKING UPSTAIRS         70               204                  56       24   \n",
       "WALKING DOWNSTAIRS       74                54                  88        1   \n",
       "SITTING                  92                35                  62      395   \n",
       "STANDING                135                97                  98       71   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    3       0  \n",
       "WALKING UPSTAIRS          70      27  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                  119       0  \n",
       "STANDING                 340       0  \n",
       "LAYING                     0     510  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "t_start = time.time()\n",
    "model_lsvm = LinearSVC(verbose=1)\n",
    "model_lsvm.fit(X_train_flatten, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lsvm.score(X_test_flatten, Y_test_label)\n",
    "print(\"\\nScore With Linear SVC on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lsvm_prediction_label = model_lsvm.predict(X_test_flatten)\n",
    "metadata_lsvm = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lsvm_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM non-linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "Score With non linear SVC on Inertial Signals = 76.96, \n",
      " Learning time = 26.88 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>407</td>\n",
       "      <td>152</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>34</td>\n",
       "      <td>261</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>113</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 407               152                 150        1   \n",
       "WALKING UPSTAIRS         34               261                  50        6   \n",
       "WALKING DOWNSTAIRS       39                58                 217        0   \n",
       "SITTING                   0                 0                   0      371   \n",
       "STANDING                 16                 0                   3      113   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    2       0  \n",
       "WALKING UPSTAIRS           0       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                   55       0  \n",
       "STANDING                 475       0  \n",
       "LAYING                     0     537  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_svm = SVC(verbose=1)\n",
    "model_svm.fit(X_train_flatten, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_svm.score(X_test_flatten, Y_test_label)\n",
    "print(\"\\nScore With non linear SVC on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "svm_prediction_label = model_svm.predict(X_test_flatten)\n",
    "metadata_svm = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(svm_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score With non Random Forest on Inertial Signals = 84.76, \n",
      " Learning time = 123.76 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>423</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>28</td>\n",
       "      <td>371</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 423                72                  29        2   \n",
       "WALKING UPSTAIRS         28               371                  18        8   \n",
       "WALKING DOWNSTAIRS       45                28                 373        0   \n",
       "SITTING                   0                 0                   0      386   \n",
       "STANDING                  0                 0                   0       95   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    1       0  \n",
       "WALKING UPSTAIRS           3       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                  120       0  \n",
       "STANDING                 408       0  \n",
       "LAYING                     0     537  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "param=[{\"n_estimators\":list(range(10,210,20))}]\n",
    "model_rf= GridSearchCV(RandomForestClassifier(),param,cv=5,n_jobs=-1)\n",
    "model_rf=model_rf.fit(X_train_flatten,Y_train_label)\n",
    "score = model_rf.score(X_test_flatten, Y_test_label)\n",
    "ypred = model_rf.predict(X_test_flatten)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"\\nScore With non Random Forest on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "rf_prediction_label = model_rf.predict(X_test_flatten)\n",
    "metadata_rf = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(rf_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score With XGBoost on Inertial Signals = 87.61, \n",
      " Learning time = 272.21 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>479</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>405</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 479                97                  50        0   \n",
       "WALKING UPSTAIRS          4               350                  21       11   \n",
       "WALKING DOWNSTAIRS       13                24                 349        0   \n",
       "SITTING                   0                 0                   0      405   \n",
       "STANDING                  0                 0                   0       75   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    1       0  \n",
       "WALKING UPSTAIRS           7       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                   62       0  \n",
       "STANDING                 462       0  \n",
       "LAYING                     0     537  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "#param=[{\"max_depth\":list(range(1,16,5)),\"n_estimators\":list(range(10,210,50)),\n",
    "#       \"learning_rate\":list([0.1,0.3,0.5,0.7,0.9])}]\n",
    "#model_gb = GridSearchCV(GradientBoostingClassifier(),param,cv=5,n_jobs=-1)\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb=model_gb.fit(X_train_flatten, Y_train_label)\n",
    "score = model_gb.score(X_test_flatten, Y_test_label)\n",
    "ypred = model_gb.predict(X_test_flatten)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"\\n Score With Gradient Boosting on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "gb_prediction_label = model_gb.predict(X_test_flatten)\n",
    "metadata_gb = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(gb_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score With XGBoost on Inertial Signals = 88.02, \n",
      " Learning time = 91.29 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>467</td>\n",
       "      <td>86</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>16</td>\n",
       "      <td>358</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 467                86                  39        0   \n",
       "WALKING UPSTAIRS         16               358                  20       13   \n",
       "WALKING DOWNSTAIRS       13                27                 361        0   \n",
       "SITTING                   0                 0                   0      409   \n",
       "STANDING                  0                 0                   0       69   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    0       0  \n",
       "WALKING UPSTAIRS           4       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                   66       0  \n",
       "STANDING                 462       0  \n",
       "LAYING                     0     537  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "t_start = time.time()\n",
    "param=[{\"n_estimators\":[50,100,200]}]\n",
    "#model_xgb =  GridSearchCV(XGBClassifier(),param,cv=10,n_jobs=-1)\n",
    "model_xgb =  XGBClassifier(n_estimators=200)\n",
    "model_xgb.fit(X_train_flatten, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_xgb.score(X_test_flatten, Y_test_label)\n",
    "print(\"\\n Score With XGBoost on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "xgb_prediction_label = model_xgb.predict(X_test_flatten)\n",
    "metadata_xgb = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(xgb_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 SVM, RF, GBM - COEFFICIENTS D'ONDELETTES\n",
    "\n",
    "### SVM Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "Score With Linear SVC on Inertial Signals (Haar) = 32.98, \n",
      " Learning time = 48.00 secondes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>147</td>\n",
       "      <td>118</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>79</td>\n",
       "      <td>108</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>135</td>\n",
       "      <td>103</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>378</td>\n",
       "      <td>406</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 147               118                 107        3   \n",
       "WALKING UPSTAIRS         79               108                  77        1   \n",
       "WALKING DOWNSTAIRS      135               103                 117        0   \n",
       "SITTING                  14                10                  14        5   \n",
       "STANDING                 44                60                  43      104   \n",
       "LAYING                   77                72                  62      378   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    3       0  \n",
       "WALKING UPSTAIRS           5       2  \n",
       "WALKING DOWNSTAIRS         7       1  \n",
       "SITTING                    2       0  \n",
       "STANDING                 109      48  \n",
       "LAYING                   406     486  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_lsvm_haar = LinearSVC(verbose=1)\n",
    "model_lsvm_haar.fit(Coeff_train, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lsvm_haar.score(Coeff_test, Y_test_label)\n",
    "print(\"\\nScore With Linear SVC on Inertial Signals (Haar) = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lsvm_haar_prediction_label = model_lsvm_haar.predict(Coeff_test)\n",
    "metadata_lsvm_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lsvm_haar_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM non-linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "Score With non linear SVC on Inertial Signals  (Haar)= 18.22, \n",
      " Learning time = 46.04 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>496</td>\n",
       "      <td>471</td>\n",
       "      <td>420</td>\n",
       "      <td>491</td>\n",
       "      <td>532</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                   0                 0                   0        0   \n",
       "WALKING UPSTAIRS          0                 0                   0        0   \n",
       "WALKING DOWNSTAIRS        0                 0                   0        0   \n",
       "SITTING                   0                 0                   0        0   \n",
       "STANDING                  0                 0                   0        0   \n",
       "LAYING                  496               471                 420      491   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    0       0  \n",
       "WALKING UPSTAIRS           0       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                    0       0  \n",
       "STANDING                   0       0  \n",
       "LAYING                   532     537  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_svm_haar = SVC(verbose=1)\n",
    "model_svm_haar.fit(Coeff_train, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_svm_haar.score(Coeff_test, Y_test_label)\n",
    "print(\"\\nScore With non linear SVC on Inertial Signals  (Haar)= %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "svm_haar_prediction_label = model_svm_haar.predict(Coeff_test)\n",
    "metadata_svm_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(svm_haar_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TCoeff_train,Coeff_train=wavelet_transformation(X_train_flatten,10,4)\n",
    "TCoeff_test,Coeff_test=wavelet_transformation(X_test_flatten,10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~94% avec seuil=4, level=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score With non Random Forest on Inertial Signals (Haar) = 93.69, \n",
      " Learning time = 58.11 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>477</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>5</td>\n",
       "      <td>457</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 477                 4                   7        0   \n",
       "WALKING UPSTAIRS          5               457                  10        2   \n",
       "WALKING DOWNSTAIRS       14                10                 403        0   \n",
       "SITTING                   0                 0                   0      392   \n",
       "STANDING                  0                 0                   0       91   \n",
       "LAYING                    0                 0                   0        6   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    0       0  \n",
       "WALKING UPSTAIRS           0       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                   36       0  \n",
       "STANDING                 495       0  \n",
       "LAYING                     1     537  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "param=[{\"n_estimators\":list(range(10,210,20))}]\n",
    "model_rf_haar= GridSearchCV(RandomForestClassifier(),param,cv=5,n_jobs=-1)\n",
    "model_rf_haar=model_rf_haar.fit(TCoeff_train,Y_train_label)\n",
    "score = model_rf_haar.score(TCoeff_test, Y_test_label)\n",
    "ypred = model_rf_haar.predict(TCoeff_test)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"\\nScore With non Random Forest on Inertial Signals (Haar) = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "rf_harr_prediction_label = model_rf_haar.predict(TCoeff_test)\n",
    "metadata_rf_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(rf_harr_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TCoeff_train,Coeff_train=wavelet_transformation(X_train_flatten,6,4)\n",
    "TCoeff_test,Coeff_test=wavelet_transformation(X_test_flatten,6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score With XGBoost on Inertial Signals = 89.55, \n",
      " Learning time = 216.90 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>471</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>19</td>\n",
       "      <td>409</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 471                44                  31        0   \n",
       "WALKING UPSTAIRS         19               409                  38        2   \n",
       "WALKING DOWNSTAIRS        6                16                 351        0   \n",
       "SITTING                   0                 2                   0      390   \n",
       "STANDING                  0                 0                   0       99   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    1       0  \n",
       "WALKING UPSTAIRS           3       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                   47       0  \n",
       "STANDING                 481       0  \n",
       "LAYING                     0     537  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "#param=[{\"max_depth\":list(range(1,16,5)),\"n_estimators\":list(range(10,210,50)),\n",
    "#       \"learning_rate\":list([0.1,0.3,0.5,0.7,0.9])}]\n",
    "#model_gb_haar = GridSearchCV(GradientBoostingClassifier(),param,cv=5,n_jobs=-1)\n",
    "model_gb_haar = GradientBoostingClassifier()\n",
    "model_gb_haar=model_gb_haar.fit(TCoeff_train, Y_train_label)\n",
    "score = model_gb_haar.score(TCoeff_test, Y_test_label)\n",
    "ypred = model_gb_haar.predict(TCoeff_test)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"\\n Score With Gradient Boosting on Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "gb_haar_prediction_label = model_gb_haar.predict(TCoeff_test)\n",
    "metadata_gb_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(gb_haar_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TCoeff_train,Coeff_train=wavelet_transformation(X_train_flatten,9,4)\n",
    "TCoeff_test,Coeff_test=wavelet_transformation(X_test_flatten,9,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score With XGBoost on Inertial Signals (Haar) = 90.36, \n",
      " Learning time = 48.99 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>474</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>15</td>\n",
       "      <td>434</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>498</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 474                21                  26        0   \n",
       "WALKING UPSTAIRS         15               434                  38        3   \n",
       "WALKING DOWNSTAIRS        7                15                 356        0   \n",
       "SITTING                   0                 1                   0      391   \n",
       "STANDING                  0                 0                   0       97   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    0       0  \n",
       "WALKING UPSTAIRS           2       0  \n",
       "WALKING DOWNSTAIRS         0       0  \n",
       "SITTING                   32      11  \n",
       "STANDING                 498      16  \n",
       "LAYING                     0     510  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "param=[{\"n_estimators\":[50,100,200]}]\n",
    "#model_xgb_haar =  GridSearchCV(XGBClassifier(),param,cv=10,n_jobs=-1)\n",
    "model_xgb_haar =  XGBClassifier(n_estimators=200)\n",
    "model_xgb_haar.fit(Coeff_train, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_xgb_haar.score(Coeff_test, Y_test_label)\n",
    "print(\"\\n Score With XGBoost on Inertial Signals (Haar) = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "xgb_haar_prediction_label = model_xgb_haar.predict(Coeff_test)\n",
    "metadata_xgb_haar = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(xgb_haar_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Deep Learning sur les données uni-dimensionnelles\n",
    "\n",
    "### Perceptron multicouche sur données brutes\n",
    "\n",
    "Un réseau de neurones classique est appris sur les données au même format que précédemment.\n",
    "\n",
    "**Q** Expliciter les choix des paramètres et donc la structure du réseau.  \n",
    "\n",
    "La taille du batch n'est pas un diviseur de la dimension de l'input (7352) mais `Keras` ne le prend pas comme une contrainte. \n",
    "\n",
    "Le réseau est composé de deux couches perceptron simples (`Denses`) séparées par une couche `Dropout`. La couche d'entrée prend en paramètre la taille des données d'entrée : comme le réseau ne contient pas de couche de convolution, les données peuvent être passées en format 1D (un vecteur de taille 1152 des séries concaténées) comme au format 2D. Elle retourne en sortie n_hidden neurones. La fonction d'activation est la fonction `relu`, largement utilisé car convexe, ce qui facilite la rétropropagation du gradient.  \n",
    "\n",
    "La couche `Dropout` permet à chaque époque de supprimer aléatoirement 50% des neurones en entrée. Ceci permet d'éviter le surapprentissage.  \n",
    "\n",
    "La couche de sortie est composée de 6 neurones qui correspondent aux 6 activités. Comme chaque neurone doit avoir une sortie binaire (1 si l'activité du neurone correspond, 0 sinon), la fonction d'activation choisie est la fonction `softmax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,094\n",
      "Trainable params: 37,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_hidden = 32\n",
    "\n",
    "n_features = X_train_flatten.shape[1]\n",
    "n_classes=6\n",
    "\n",
    "\n",
    "model_base_mlp_u =km.Sequential()\n",
    "model_base_mlp_u.add(kl.Dense(n_hidden, input_shape=(n_features,),  activation = \"relu\"))\n",
    "#model_base_mlp_u.add(kl.Dropout(0.5))\n",
    "#model_base_mlp_u.add(kl.Dense(16,  activation = \"relu\"))\n",
    "model_base_mlp_u.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_mlp_u.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model_base_mlp_u.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.8213 - acc: 0.7107 - val_loss: 0.8012 - val_acc: 0.7496\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.4011 - acc: 0.8768 - val_loss: 0.5691 - val_acc: 0.8327\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2517 - acc: 0.9161 - val_loss: 0.4821 - val_acc: 0.8446\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1896 - acc: 0.9329 - val_loss: 0.4289 - val_acc: 0.8714\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1554 - acc: 0.9425 - val_loss: 0.4096 - val_acc: 0.8785\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1347 - acc: 0.9493 - val_loss: 0.4368 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1234 - acc: 0.9517 - val_loss: 0.4404 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1145 - acc: 0.9520 - val_loss: 0.4799 - val_acc: 0.8677\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1094 - acc: 0.9525 - val_loss: 0.4875 - val_acc: 0.8707\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1035 - acc: 0.9543 - val_loss: 0.4662 - val_acc: 0.8765\n",
      "2848/2947 [===========================>..] - ETA: 0s\n",
      "Score With Simple MLP on Inertial Signals = 87.65, \n",
      "Learning time = 8.51 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>440</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      368        99        0                   0   \n",
       "STANDING                 0       75       449        0                   4   \n",
       "WALKING                  0        5         3      440                  27   \n",
       "WALKING_DOWNSTAIRS       0        8         7        1                 393   \n",
       "WALKING_UPSTAIRS         0        3         3       23                  19   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                           24  \n",
       "STANDING                           4  \n",
       "WALKING                           21  \n",
       "WALKING_DOWNSTAIRS                11  \n",
       "WALKING_UPSTAIRS                 423  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp_u.fit(X_train_flatten,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test_flatten, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp_u.evaluate(X_test_flatten, Y_test_dummies)[1] \n",
    "print(\"\\nScore With Simple MLP on Inertial Signals = %.2f, \\nLearning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp_u = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_u_prediction = model_base_mlp_u.predict(X_test_flatten)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_u_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q ** : Que conclure sur ces résultats en terme de performance, de temps d'apprentissage? Comparer avec la regression logistique?  \n",
    "\n",
    "Ce réseau de neurones relativement simple obtient de bien meilleurs résultats sur les données brutes que la régression logistique. Mise à part l'activité `Walking_upstairs`, les classes actives et passives sont assez bien discriminées. Il reste cependant des améliorations à faire intra classes (actives et passives). \n",
    "\n",
    "Au niveau du temps de calcul, sous l'environnement GPU l'importation des données met 25 secondes, mais l'exécution de l'algorithme est très rapide : moins de 7 secondes. Une fois les données importées, le réseau de neurones est donc plus rapide que la régression logistique. \n",
    "\n",
    "** Exo ** : Quelle est l'influence de l'ajout de nouvelle couche? Supression du Dropout?  \n",
    "\n",
    "L'ajout d'une couche `Dense` avec 32 ou 16 neurones n'améliore pas la performance du réseau. Au contraire, cela contribue à augmenter le temps d'exécution, donc il ne vaut mieux ne pas la mettre. \n",
    "\n",
    "La suppression de la couche `Dropout` permet de diminuer la fonction perte sur l'échantillon test et on obtient de meilleurs résultats. Elle n'est donc pas nécessaire dans ce cas là, d'autant que le temps gagné par sa présence est minime (environ 1sec). \n",
    "\n",
    "### Perceptron multicouche - Coefficients d'ondelettes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TCoeff_train,Coeff_train=wavelet_transformation(X_train_flatten,9)\n",
    "TCoeff_test,Coeff_test=wavelet_transformation(X_test_flatten,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_hidden = 32\n",
    "n_features = Coeff_train.shape[1]\n",
    "n_classes=6\n",
    "\n",
    "model_base_mlp_u =km.Sequential()\n",
    "model_base_mlp_u.add(kl.Dense(n_hidden, input_shape=(n_features,),  activation = \"relu\"))\n",
    "#model_base_mlp_u.add(kl.Dropout(0.5))\n",
    "#model_base_mlp_u.add(kl.Dense(16,  activation = \"relu\"))\n",
    "model_base_mlp_u.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_mlp_u.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1073 - acc: 0.9591 - val_loss: 0.3050 - val_acc: 0.9013\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1044 - acc: 0.9589 - val_loss: 0.3018 - val_acc: 0.8996\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1016 - acc: 0.9592 - val_loss: 0.3156 - val_acc: 0.8999\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0988 - acc: 0.9612 - val_loss: 0.3229 - val_acc: 0.8979\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0964 - acc: 0.9615 - val_loss: 0.3374 - val_acc: 0.9036\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0940 - acc: 0.9640 - val_loss: 0.3417 - val_acc: 0.9009\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0915 - acc: 0.9634 - val_loss: 0.3565 - val_acc: 0.9002\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0890 - acc: 0.9661 - val_loss: 0.3646 - val_acc: 0.9009\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0873 - acc: 0.9668 - val_loss: 0.3751 - val_acc: 0.9009\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0843 - acc: 0.9676 - val_loss: 0.3880 - val_acc: 0.9033\n",
      "2496/2947 [========================>.....] - ETA: 0s\n",
      "Score With Simple MLP on Inertial Signals (Haar) = 90.33, \n",
      "Learning time = 6.71 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>449</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>382</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 537        0         0        0                   0   \n",
       "SITTING                  0      395        94        0                   0   \n",
       "STANDING                 0       66       466        0                   0   \n",
       "WALKING                  1        3         9      449                  23   \n",
       "WALKING_DOWNSTAIRS       1        6         9        5                 382   \n",
       "WALKING_UPSTAIRS         1        2         3       22                  10   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                             0  \n",
       "SITTING                            2  \n",
       "STANDING                           0  \n",
       "WALKING                           11  \n",
       "WALKING_DOWNSTAIRS                17  \n",
       "WALKING_UPSTAIRS                 433  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp_u.fit(Coeff_train,  Y_train_dummies, batch_size=batch_size, validation_data=(Coeff_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp_u.evaluate(Coeff_test, Y_test_dummies)[1] \n",
    "print(\"\\nScore With Simple MLP on Inertial Signals (Haar) = %.2f, \\nLearning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp_u = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_u_prediction = model_base_mlp_u.predict(Coeff_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_u_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce réseau de neurones là, projeter sur la base d'ondelettes semble améliorer la prédiction. \n",
    "\n",
    "## 5 Deep Learning sur les signaux multidimensionnels\n",
    "Les différents signaux ne sont pas concaténées en un seul signal mais pris en compte parallèlement.\n",
    "\n",
    "### 5.1 Perceptron multichouche\n",
    "**Q** Expliciter les choix des paramètres et donc la structure du réseau.\n",
    "\n",
    "Le réseau entrainé est le même que précédemment à la différence que les données d'entrées ne sont pas sous le même format. Les séries n'ont pas été concaténées donc on passe en entrée une matrice. `Input_dim` correspond au nombre de séries et `timesteps` à la longueur d'une série. La couche reshape permet de repasser au format 1D. \n",
    "\n",
    "On a supprimé la couche `Dropout` jugée inutile dans ce cas là. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 32\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "model_base_mlp =km.Sequential()\n",
    "model_base_mlp.add(kl.Dense(n_hidden, input_shape=(timesteps, input_dim),  activation = \"relu\"))\n",
    "model_base_mlp.add(kl.Reshape((timesteps*n_hidden,) , input_shape= (timesteps, n_hidden)  ))\n",
    "model_base_mlp.add(kl.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_base_mlp.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 0s - loss: 1.3295 - acc: 0.4603 - val_loss: 1.0828 - val_acc: 0.5809\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.8868 - acc: 0.6704 - val_loss: 0.9261 - val_acc: 0.6386\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.6613 - acc: 0.7776 - val_loss: 0.7605 - val_acc: 0.7754\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.4274 - acc: 0.8921 - val_loss: 0.7643 - val_acc: 0.8076\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2885 - acc: 0.9233 - val_loss: 0.6907 - val_acc: 0.8449\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2096 - acc: 0.9355 - val_loss: 0.6647 - val_acc: 0.8554\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1786 - acc: 0.9362 - val_loss: 0.6712 - val_acc: 0.8578\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1607 - acc: 0.9402 - val_loss: 0.6521 - val_acc: 0.8531\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1479 - acc: 0.9397 - val_loss: 0.6701 - val_acc: 0.8541\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1387 - acc: 0.9419 - val_loss: 0.6572 - val_acc: 0.8558\n",
      "2208/2947 [=====================>........] - ETA: 0s\n",
      "Score With Simple MLP on Multidimensional Inertial Signals = 85.58, \n",
      "Learning time = 8.53 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>468</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>397</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>33</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      339       128        0                   0   \n",
       "STANDING                 0       59       468        2                   0   \n",
       "WALKING                  0        0         0      432                  57   \n",
       "WALKING_DOWNSTAIRS       0        0         0       20                 397   \n",
       "WALKING_UPSTAIRS         0        0         0       62                  33   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                           24  \n",
       "STANDING                           3  \n",
       "WALKING                            7  \n",
       "WALKING_DOWNSTAIRS                 3  \n",
       "WALKING_UPSTAIRS                 376  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"\\nScore With Simple MLP on Multidimensional Inertial Signals = %.2f, \\nLearning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_prediction = model_base_mlp.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128, 32)           320       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 24,902\n",
      "Trainable params: 24,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 *Long Short Time Memory (LSTM)*\n",
    "Test d'un réseau avec couche LSTM avec l'idée d'appréhender la structure temporelle des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 32\n",
    "#default stateful = False\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "batch_size=64\n",
    "#else:\n",
    "model_base_lstm =km.Sequential()\n",
    "model_base_lstm.add(kl.LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "model_base_lstm.add(kl.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_base_lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model_base_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 14s - loss: 1.5166 - acc: 0.3399 - val_loss: 1.3017 - val_acc: 0.4676\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 14s - loss: 1.1683 - acc: 0.5095 - val_loss: 1.2444 - val_acc: 0.4900\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 14s - loss: 1.1034 - acc: 0.5329 - val_loss: 1.1649 - val_acc: 0.5171\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 15s - loss: 1.0324 - acc: 0.5811 - val_loss: 1.1400 - val_acc: 0.5188\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 15s - loss: 0.9367 - acc: 0.6646 - val_loss: 1.0606 - val_acc: 0.6227\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 14s - loss: 0.8064 - acc: 0.7210 - val_loss: 0.8702 - val_acc: 0.6804\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 14s - loss: 0.7379 - acc: 0.7337 - val_loss: 0.8273 - val_acc: 0.7119\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 13s - loss: 0.6704 - acc: 0.7714 - val_loss: 0.7576 - val_acc: 0.7435\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 14s - loss: 0.5873 - acc: 0.7965 - val_loss: 0.7211 - val_acc: 0.7499\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 14s - loss: 0.5490 - acc: 0.8221 - val_loss: 0.7649 - val_acc: 0.7530\n",
      "2944/2947 [============================>.] - ETA: 0s\n",
      " Score With Simple MLP on Multidimensional Inertial Signals = 75.30, \n",
      "Learning time = 146.68 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>453</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "      <td>236</td>\n",
       "      <td>38</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>290</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      364       101       21                   1   \n",
       "STANDING                 0       59       453        2                   2   \n",
       "WALKING                  0       11        88      236                  38   \n",
       "WALKING_DOWNSTAIRS       0        4        11       71                 290   \n",
       "WALKING_UPSTAIRS         0        6        16       43                  40   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                            4  \n",
       "STANDING                          16  \n",
       "WALKING                          123  \n",
       "WALKING_DOWNSTAIRS                44  \n",
       "WALKING_UPSTAIRS                 366  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default shuffle = True Meilleur avec Shuffle m True\n",
    "t_start = time.time()\n",
    "model_base_lstm.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs, shuffle=False)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_lstm.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"\\n Score With Simple MLP on Multidimensional Inertial Signals = %.2f, \\nLearning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_lstm = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_lstm_prediction = model_base_lstm.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_lstm_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Réseau avec couche convolutionelle 1D (*ConvNet*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 120, 32)           2624      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 7686      \n",
      "=================================================================\n",
      "Total params: 10,310\n",
      "Trainable params: 10,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "#else:\n",
    "model_base_conv_1D =km.Sequential()\n",
    "model_base_conv_1D.add(kl.Conv1D(32, 9, activation='relu', input_shape=(timesteps, input_dim)))\n",
    "model_base_conv_1D.add(kl.MaxPooling1D(pool_size=3))\n",
    "model_base_conv_1D.add(kl.Flatten())\n",
    "model_base_conv_1D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_1D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_base_conv_1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.7116 - acc: 0.7461 - val_loss: 0.6099 - val_acc: 0.7798\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.3128 - acc: 0.8947 - val_loss: 0.3831 - val_acc: 0.8724\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1836 - acc: 0.9354 - val_loss: 0.3303 - val_acc: 0.8955\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1401 - acc: 0.9465 - val_loss: 0.2532 - val_acc: 0.9155\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1208 - acc: 0.9520 - val_loss: 0.2548 - val_acc: 0.9155\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1129 - acc: 0.9527 - val_loss: 0.2549 - val_acc: 0.9162\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1054 - acc: 0.9544 - val_loss: 0.2741 - val_acc: 0.9135\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1023 - acc: 0.9550 - val_loss: 0.2457 - val_acc: 0.9196\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0991 - acc: 0.9572 - val_loss: 0.2251 - val_acc: 0.9179\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.0967 - acc: 0.9592 - val_loss: 0.2395 - val_acc: 0.9162\n",
      "2496/2947 [========================>.....] - ETA: 0s\n",
      " Score With Conv on Multidimensional Inertial Signals = 91.62, \n",
      " Learning time = 4.12 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>453</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>397</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 537        0         0        0                   0   \n",
       "SITTING                  0      378       108        0                   0   \n",
       "STANDING                 0       76       453        1                   0   \n",
       "WALKING                  0        0         0      488                   3   \n",
       "WALKING_DOWNSTAIRS       0        0         0        2                 397   \n",
       "WALKING_UPSTAIRS         0        0         0        4                  20   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                             0  \n",
       "SITTING                            5  \n",
       "STANDING                           2  \n",
       "WALKING                            5  \n",
       "WALKING_DOWNSTAIRS                21  \n",
       "WALKING_UPSTAIRS                 447  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_conv_1D.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_1D.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"\\n Score With Conv on Multidimensional Inertial Signals = %.2f, \\n Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_1D_prediction = model_base_conv_1D.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_conv_1D_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Réseau avec couche convolutionelle 2D (*ConvNet*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 1, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 12102     \n",
      "=================================================================\n",
      "Total params: 12,998\n",
      "Trainable params: 12,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "X_train_conv = X_train.reshape(N_train, timesteps, input_dim, 1)\n",
    "X_test_conv = X_test.reshape(N_test, timesteps, input_dim, 1)\n",
    "\n",
    "#else:\n",
    "model_base_conv_2D =km.Sequential()\n",
    "model_base_conv_2D.add(kl.Conv2D(32, (3, 9), activation='relu', input_shape=(timesteps, input_dim, 1)))\n",
    "model_base_conv_2D.add(kl.MaxPooling2D(pool_size=(2, 1)))\n",
    "model_base_conv_2D.add(kl.Flatten())\n",
    "model_base_conv_2D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_2D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_base_conv_2D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.7481 - acc: 0.7237 - val_loss: 0.6775 - val_acc: 0.7523\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.4031 - acc: 0.8545 - val_loss: 0.5844 - val_acc: 0.7716\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2944 - acc: 0.8987 - val_loss: 0.4723 - val_acc: 0.8378\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2232 - acc: 0.9236 - val_loss: 0.4040 - val_acc: 0.8629\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1820 - acc: 0.9358 - val_loss: 0.3756 - val_acc: 0.8609\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1594 - acc: 0.9430 - val_loss: 0.3193 - val_acc: 0.8795\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1439 - acc: 0.9452 - val_loss: 0.3341 - val_acc: 0.8724\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1329 - acc: 0.9498 - val_loss: 0.3246 - val_acc: 0.8836\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1253 - acc: 0.9510 - val_loss: 0.3284 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.1199 - acc: 0.9536 - val_loss: 0.3016 - val_acc: 0.8867\n",
      "1536/2947 [==============>...............] - ETA: 0s\n",
      " Score With Conv on Multidimensional Inertial Signals = 88.67, \n",
      " Learning time = 4.03 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>1</td>\n",
       "      <td>380</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>435</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  1      380       102        1                   0   \n",
       "STANDING                 0       78       453        0                   0   \n",
       "WALKING                  0        0         0      435                  57   \n",
       "WALKING_DOWNSTAIRS       0        1         0       12                 405   \n",
       "WALKING_UPSTAIRS         0        0         0       13                  28   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                            7  \n",
       "STANDING                           1  \n",
       "WALKING                            4  \n",
       "WALKING_DOWNSTAIRS                 2  \n",
       "WALKING_UPSTAIRS                 430  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_conv_2D.fit(X_train_conv,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test_conv, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_2D.evaluate(X_test_conv, Y_test_dummies)[1] \n",
    "print(\"\\n Score With Conv on Multidimensional Inertial Signals = %.2f, \\nLearning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_2D_prediction = model_base_conv_2D.predict(X_test_conv)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_conv_2D_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention au sur-apprentissage** A force de rechercher la meilleure architecture en minimisant l'erreur sur l'échantillon test, celle finalement trouvée peut y être très adaptée réduisant ainsi la capacité de généralisation. Il serait prudent de multiplier le découpage de l'échantillon par validation croisée *Monte Carlo*.\n",
    "\n",
    "### 5.5 Implémentation de la Validation Croisée de Monte Carlo\n",
    "\n",
    "**Objectif** trouver la meilleure architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 6)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.copy(np.concatenate((X_train, X_test), axis=0))\n",
    "Y=np.copy(np.concatenate((Y_train_dummies, Y_test_dummies), axis=0))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_hidden = 32\n",
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ***************** 0 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6574 - acc: 0.7389 - val_loss: 0.4322 - val_acc: 0.8175\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3577 - acc: 0.8649 - val_loss: 0.2989 - val_acc: 0.8806\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2618 - acc: 0.9036 - val_loss: 0.2488 - val_acc: 0.9049\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2159 - acc: 0.9186 - val_loss: 0.2403 - val_acc: 0.9083\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1877 - acc: 0.9255 - val_loss: 0.2392 - val_acc: 0.8961\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1702 - acc: 0.9359 - val_loss: 0.1874 - val_acc: 0.9325\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1564 - acc: 0.9392 - val_loss: 0.1945 - val_acc: 0.9262\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1464 - acc: 0.9447 - val_loss: 0.2115 - val_acc: 0.9146\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1375 - acc: 0.9467 - val_loss: 0.1919 - val_acc: 0.9267\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1311 - acc: 0.9496 - val_loss: 0.2613 - val_acc: 0.8956\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5717 - acc: 0.7852 - val_loss: 0.2685 - val_acc: 0.9068\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1996 - acc: 0.9291 - val_loss: 0.1966 - val_acc: 0.9165\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1396 - acc: 0.9455 - val_loss: 0.1262 - val_acc: 0.9461\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1243 - acc: 0.9500 - val_loss: 0.1234 - val_acc: 0.9524\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1150 - acc: 0.9540 - val_loss: 0.1110 - val_acc: 0.9558\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1087 - acc: 0.9538 - val_loss: 0.1168 - val_acc: 0.9510\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1058 - acc: 0.9587 - val_loss: 0.1789 - val_acc: 0.9311\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1025 - acc: 0.9602 - val_loss: 0.1072 - val_acc: 0.9568\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0990 - acc: 0.9610 - val_loss: 0.1197 - val_acc: 0.9568\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0996 - acc: 0.9613 - val_loss: 0.1098 - val_acc: 0.9597\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6537 - acc: 0.7536 - val_loss: 0.3814 - val_acc: 0.8723\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3195 - acc: 0.8874 - val_loss: 0.2655 - val_acc: 0.9058\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2282 - acc: 0.9149 - val_loss: 0.2085 - val_acc: 0.9218\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1854 - acc: 0.9307 - val_loss: 0.2127 - val_acc: 0.9209\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1590 - acc: 0.9399 - val_loss: 0.1660 - val_acc: 0.9379\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1437 - acc: 0.9459 - val_loss: 0.1592 - val_acc: 0.9427\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1319 - acc: 0.9479 - val_loss: 0.1394 - val_acc: 0.9476\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1249 - acc: 0.9500 - val_loss: 0.1371 - val_acc: 0.9466\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1182 - acc: 0.9559 - val_loss: 0.1394 - val_acc: 0.9471\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1139 - acc: 0.9559 - val_loss: 0.1457 - val_acc: 0.9476\n",
      "1536/2060 [=====================>........] - ETA: 0s\n",
      " \n",
      " ***************** 1 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6250 - acc: 0.7451 - val_loss: 0.4791 - val_acc: 0.8049\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3767 - acc: 0.8574 - val_loss: 0.3262 - val_acc: 0.8796\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2778 - acc: 0.8989 - val_loss: 0.2769 - val_acc: 0.9044\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2239 - acc: 0.9171 - val_loss: 0.2167 - val_acc: 0.9228\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1921 - acc: 0.9289 - val_loss: 0.2017 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1712 - acc: 0.9370 - val_loss: 0.1769 - val_acc: 0.9364\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1574 - acc: 0.9428 - val_loss: 0.2041 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1451 - acc: 0.9443 - val_loss: 0.1764 - val_acc: 0.9345\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1373 - acc: 0.9501 - val_loss: 0.1837 - val_acc: 0.9316\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1320 - acc: 0.9494 - val_loss: 0.1771 - val_acc: 0.9413\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5637 - acc: 0.7986 - val_loss: 0.2990 - val_acc: 0.8990\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1996 - acc: 0.9275 - val_loss: 0.1516 - val_acc: 0.9505\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1419 - acc: 0.9443 - val_loss: 0.1163 - val_acc: 0.9592\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1252 - acc: 0.9482 - val_loss: 0.1024 - val_acc: 0.9641\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1168 - acc: 0.9523 - val_loss: 0.1038 - val_acc: 0.9558\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1105 - acc: 0.9555 - val_loss: 0.0978 - val_acc: 0.9684\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1079 - acc: 0.9565 - val_loss: 0.0949 - val_acc: 0.9626\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1056 - acc: 0.9573 - val_loss: 0.0902 - val_acc: 0.9680\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1011 - acc: 0.9602 - val_loss: 0.0964 - val_acc: 0.9626\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0991 - acc: 0.9629 - val_loss: 0.0964 - val_acc: 0.9680\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6725 - acc: 0.7443 - val_loss: 0.4605 - val_acc: 0.8306\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3392 - acc: 0.8797 - val_loss: 0.2659 - val_acc: 0.9097\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2344 - acc: 0.9150 - val_loss: 0.1915 - val_acc: 0.9311\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1880 - acc: 0.9288 - val_loss: 0.1766 - val_acc: 0.9383\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1626 - acc: 0.9382 - val_loss: 0.1495 - val_acc: 0.9534\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1459 - acc: 0.9433 - val_loss: 0.1305 - val_acc: 0.9568\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1358 - acc: 0.9487 - val_loss: 0.1470 - val_acc: 0.9481\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1271 - acc: 0.9506 - val_loss: 0.1165 - val_acc: 0.9558\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1202 - acc: 0.9550 - val_loss: 0.1340 - val_acc: 0.9485\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1146 - acc: 0.9580 - val_loss: 0.1348 - val_acc: 0.9505\n",
      "1216/2060 [================>.............] - ETA: 0s\n",
      " \n",
      " ***************** 2 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8239/8239 [==============================] - 1s - loss: 0.6293 - acc: 0.7389 - val_loss: 0.5252 - val_acc: 0.7806\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3993 - acc: 0.8423 - val_loss: 0.3634 - val_acc: 0.8743\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2935 - acc: 0.8914 - val_loss: 0.2845 - val_acc: 0.9024\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2327 - acc: 0.9182 - val_loss: 0.2471 - val_acc: 0.9189\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1970 - acc: 0.9296 - val_loss: 0.2479 - val_acc: 0.9087\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1760 - acc: 0.9348 - val_loss: 0.2192 - val_acc: 0.9155\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1606 - acc: 0.9392 - val_loss: 0.1956 - val_acc: 0.9262\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1511 - acc: 0.9427 - val_loss: 0.1960 - val_acc: 0.9248\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1402 - acc: 0.9461 - val_loss: 0.1962 - val_acc: 0.9228\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1327 - acc: 0.9487 - val_loss: 0.1929 - val_acc: 0.9248\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5775 - acc: 0.7893 - val_loss: 0.2687 - val_acc: 0.9107\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1951 - acc: 0.9314 - val_loss: 0.1527 - val_acc: 0.9345\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1368 - acc: 0.9455 - val_loss: 0.1355 - val_acc: 0.9403\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1193 - acc: 0.9488 - val_loss: 0.1256 - val_acc: 0.9524\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.956 - 0s - loss: 0.1079 - acc: 0.9557 - val_loss: 0.1549 - val_acc: 0.9432\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1049 - acc: 0.9573 - val_loss: 0.1194 - val_acc: 0.9573\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.0991 - acc: 0.9599 - val_loss: 0.1173 - val_acc: 0.9592\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.0988 - acc: 0.9601 - val_loss: 0.1039 - val_acc: 0.9617\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0949 - acc: 0.9629 - val_loss: 0.1093 - val_acc: 0.9544\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.0921 - acc: 0.9643 - val_loss: 0.0981 - val_acc: 0.9646\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6675 - acc: 0.7342 - val_loss: 0.4995 - val_acc: 0.7976\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3524 - acc: 0.8729 - val_loss: 0.3004 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2396 - acc: 0.9131 - val_loss: 0.2233 - val_acc: 0.9267\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1892 - acc: 0.9297 - val_loss: 0.1954 - val_acc: 0.9189\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1642 - acc: 0.9419 - val_loss: 0.1976 - val_acc: 0.9150\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1461 - acc: 0.9426 - val_loss: 0.1637 - val_acc: 0.9286\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1343 - acc: 0.9496 - val_loss: 0.1996 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1259 - acc: 0.9527 - val_loss: 0.1536 - val_acc: 0.9471\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1177 - acc: 0.9568 - val_loss: 0.1481 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1131 - acc: 0.9559 - val_loss: 0.1309 - val_acc: 0.9519\n",
      "1216/2060 [================>.............] - ETA: 0s\n",
      " \n",
      " ***************** 3 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6331 - acc: 0.7443 - val_loss: 0.4310 - val_acc: 0.8262\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3582 - acc: 0.8672 - val_loss: 0.3046 - val_acc: 0.8981\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2716 - acc: 0.9012 - val_loss: 0.2569 - val_acc: 0.8932\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2271 - acc: 0.9186 - val_loss: 0.2513 - val_acc: 0.8903\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1994 - acc: 0.9266 - val_loss: 0.2066 - val_acc: 0.9107\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1808 - acc: 0.9320 - val_loss: 0.2079 - val_acc: 0.9068\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1687 - acc: 0.9391 - val_loss: 0.1977 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1545 - acc: 0.9404 - val_loss: 0.2050 - val_acc: 0.9121\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1450 - acc: 0.9454 - val_loss: 0.1734 - val_acc: 0.9350\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1383 - acc: 0.9466 - val_loss: 0.1856 - val_acc: 0.9160\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5744 - acc: 0.7938 - val_loss: 0.2911 - val_acc: 0.9053\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1995 - acc: 0.9313 - val_loss: 0.1585 - val_acc: 0.9364\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1375 - acc: 0.9451 - val_loss: 0.1351 - val_acc: 0.9364\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1212 - acc: 0.9521 - val_loss: 0.1181 - val_acc: 0.9592\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1110 - acc: 0.9553 - val_loss: 0.1026 - val_acc: 0.9597\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1076 - acc: 0.9536 - val_loss: 0.1060 - val_acc: 0.9485\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1027 - acc: 0.9585 - val_loss: 0.1067 - val_acc: 0.9617\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0997 - acc: 0.9601 - val_loss: 0.0947 - val_acc: 0.9689\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0969 - acc: 0.9616 - val_loss: 0.1022 - val_acc: 0.9612\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0960 - acc: 0.9619 - val_loss: 0.0925 - val_acc: 0.9684\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6566 - acc: 0.7461 - val_loss: 0.4379 - val_acc: 0.8214\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3243 - acc: 0.8842 - val_loss: 0.2646 - val_acc: 0.8947\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2259 - acc: 0.9188 - val_loss: 0.2120 - val_acc: 0.9126\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1830 - acc: 0.9324 - val_loss: 0.1882 - val_acc: 0.9180\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1605 - acc: 0.9409 - val_loss: 0.1603 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1455 - acc: 0.9442 - val_loss: 0.1864 - val_acc: 0.9175\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1356 - acc: 0.9473 - val_loss: 0.1942 - val_acc: 0.9141\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1271 - acc: 0.9504 - val_loss: 0.1504 - val_acc: 0.9345\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1201 - acc: 0.9531 - val_loss: 0.1304 - val_acc: 0.9529\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1164 - acc: 0.9570 - val_loss: 0.1268 - val_acc: 0.9515\n",
      "1248/2060 [=================>............] - ETA: 0s\n",
      " \n",
      " ***************** 4 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6486 - acc: 0.7349 - val_loss: 0.5566 - val_acc: 0.7607\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3899 - acc: 0.8461 - val_loss: 0.3956 - val_acc: 0.8549\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2945 - acc: 0.8868 - val_loss: 0.3009 - val_acc: 0.8801\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2386 - acc: 0.9159 - val_loss: 0.2829 - val_acc: 0.8947\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2044 - acc: 0.9272 - val_loss: 0.2164 - val_acc: 0.9180\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1857 - acc: 0.9279 - val_loss: 0.2443 - val_acc: 0.9083\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1690 - acc: 0.9389 - val_loss: 0.1953 - val_acc: 0.9223\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1558 - acc: 0.9425 - val_loss: 0.1964 - val_acc: 0.9218\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1482 - acc: 0.9467 - val_loss: 0.1941 - val_acc: 0.9248\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1392 - acc: 0.9483 - val_loss: 0.1819 - val_acc: 0.9277\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5994 - acc: 0.7796 - val_loss: 0.2907 - val_acc: 0.9112\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2135 - acc: 0.9246 - val_loss: 0.1773 - val_acc: 0.9223\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1484 - acc: 0.9402 - val_loss: 0.1481 - val_acc: 0.9393\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1261 - acc: 0.9502 - val_loss: 0.1211 - val_acc: 0.9490\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1159 - acc: 0.9524 - val_loss: 0.1183 - val_acc: 0.9471\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1083 - acc: 0.9559 - val_loss: 0.1119 - val_acc: 0.9466\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1045 - acc: 0.9578 - val_loss: 0.1120 - val_acc: 0.9549\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1002 - acc: 0.9610 - val_loss: 0.1101 - val_acc: 0.9500\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0971 - acc: 0.9620 - val_loss: 0.1223 - val_acc: 0.9549\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0949 - acc: 0.9615 - val_loss: 0.1020 - val_acc: 0.9553\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6350 - acc: 0.7529 - val_loss: 0.4341 - val_acc: 0.8413\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3241 - acc: 0.8808 - val_loss: 0.2724 - val_acc: 0.9083\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2253 - acc: 0.9226 - val_loss: 0.2125 - val_acc: 0.9199\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1818 - acc: 0.9318 - val_loss: 0.1838 - val_acc: 0.9345\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1593 - acc: 0.9414 - val_loss: 0.1890 - val_acc: 0.9223\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1439 - acc: 0.9474 - val_loss: 0.1604 - val_acc: 0.9403\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1335 - acc: 0.9515 - val_loss: 0.1482 - val_acc: 0.9417\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1282 - acc: 0.9545 - val_loss: 0.1354 - val_acc: 0.9471\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1227 - acc: 0.9552 - val_loss: 0.1361 - val_acc: 0.9432\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1167 - acc: 0.9580 - val_loss: 0.1352 - val_acc: 0.9481\n",
      "1216/2060 [================>.............] - ETA: 0s\n",
      " \n",
      " ***************** 5 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6433 - acc: 0.7360 - val_loss: 0.5614 - val_acc: 0.7748\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.4061 - acc: 0.8448 - val_loss: 0.4552 - val_acc: 0.8083\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3140 - acc: 0.8832 - val_loss: 0.3143 - val_acc: 0.8733\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2604 - acc: 0.9053 - val_loss: 0.3238 - val_acc: 0.8825\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2275 - acc: 0.9153 - val_loss: 0.2639 - val_acc: 0.9058\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2015 - acc: 0.9217 - val_loss: 0.2299 - val_acc: 0.9136\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1822 - acc: 0.9309 - val_loss: 0.2376 - val_acc: 0.9005\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1690 - acc: 0.9362 - val_loss: 0.2180 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1571 - acc: 0.9393 - val_loss: 0.2045 - val_acc: 0.9238\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1473 - acc: 0.9444 - val_loss: 0.2149 - val_acc: 0.9141\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5713 - acc: 0.7883 - val_loss: 0.2920 - val_acc: 0.9184\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2031 - acc: 0.9263 - val_loss: 0.1627 - val_acc: 0.9408\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1425 - acc: 0.9423 - val_loss: 0.1345 - val_acc: 0.9515\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1232 - acc: 0.9501 - val_loss: 0.1273 - val_acc: 0.9456\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1107 - acc: 0.9550 - val_loss: 0.1206 - val_acc: 0.9573\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1047 - acc: 0.9556 - val_loss: 0.1196 - val_acc: 0.9592\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1014 - acc: 0.9610 - val_loss: 0.1140 - val_acc: 0.9578\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0980 - acc: 0.9597 - val_loss: 0.1152 - val_acc: 0.9602\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0965 - acc: 0.9612 - val_loss: 0.1177 - val_acc: 0.9529\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0935 - acc: 0.9638 - val_loss: 0.1142 - val_acc: 0.9607\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6220 - acc: 0.7568 - val_loss: 0.4463 - val_acc: 0.8398\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3101 - acc: 0.8925 - val_loss: 0.2828 - val_acc: 0.9024\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2179 - acc: 0.9229 - val_loss: 0.2120 - val_acc: 0.9165\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1795 - acc: 0.9312 - val_loss: 0.1749 - val_acc: 0.9369\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1548 - acc: 0.9425 - val_loss: 0.1767 - val_acc: 0.9374\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1410 - acc: 0.9461 - val_loss: 0.1853 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1335 - acc: 0.9485 - val_loss: 0.1449 - val_acc: 0.9485\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1214 - acc: 0.9523 - val_loss: 0.1507 - val_acc: 0.9466\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1190 - acc: 0.9538 - val_loss: 0.1620 - val_acc: 0.9383\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1124 - acc: 0.9561 - val_loss: 0.1443 - val_acc: 0.9403\n",
      "1376/2060 [===================>..........] - ETA: 0s\n",
      " \n",
      " ***************** 6 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8239/8239 [==============================] - 1s - loss: 0.6374 - acc: 0.7418 - val_loss: 0.4451 - val_acc: 0.8286\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3861 - acc: 0.8550 - val_loss: 0.3793 - val_acc: 0.8553\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2915 - acc: 0.8946 - val_loss: 0.2770 - val_acc: 0.8913\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2408 - acc: 0.9092 - val_loss: 0.2382 - val_acc: 0.9102\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2059 - acc: 0.9235 - val_loss: 0.2211 - val_acc: 0.9097\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1824 - acc: 0.9315 - val_loss: 0.2106 - val_acc: 0.9146\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1647 - acc: 0.9366 - val_loss: 0.2094 - val_acc: 0.9189\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1529 - acc: 0.9432 - val_loss: 0.2135 - val_acc: 0.9160\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1451 - acc: 0.9461 - val_loss: 0.1918 - val_acc: 0.9267\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1374 - acc: 0.9461 - val_loss: 0.1974 - val_acc: 0.9286\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6078 - acc: 0.7736 - val_loss: 0.3148 - val_acc: 0.8903\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2304 - acc: 0.9211 - val_loss: 0.1717 - val_acc: 0.9325\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1513 - acc: 0.9421 - val_loss: 0.1315 - val_acc: 0.9427\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1262 - acc: 0.9495 - val_loss: 0.1497 - val_acc: 0.9505\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1165 - acc: 0.9544 - val_loss: 0.1061 - val_acc: 0.9558\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1112 - acc: 0.9553 - val_loss: 0.1064 - val_acc: 0.9573\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1037 - acc: 0.9572 - val_loss: 0.1091 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1008 - acc: 0.9620 - val_loss: 0.1138 - val_acc: 0.9534\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0971 - acc: 0.9633 - val_loss: 0.1088 - val_acc: 0.9617\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0958 - acc: 0.9632 - val_loss: 0.1082 - val_acc: 0.9553\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6652 - acc: 0.7371 - val_loss: 0.4407 - val_acc: 0.8267\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3518 - acc: 0.8673 - val_loss: 0.2835 - val_acc: 0.8942\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2502 - acc: 0.9082 - val_loss: 0.2367 - val_acc: 0.9223\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2021 - acc: 0.9249 - val_loss: 0.2139 - val_acc: 0.9053\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1727 - acc: 0.9356 - val_loss: 0.1718 - val_acc: 0.9330\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1518 - acc: 0.9440 - val_loss: 0.1686 - val_acc: 0.9364\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1366 - acc: 0.9491 - val_loss: 0.1554 - val_acc: 0.9456\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1274 - acc: 0.9512 - val_loss: 0.1402 - val_acc: 0.9471\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1166 - acc: 0.9584 - val_loss: 0.1800 - val_acc: 0.9350\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1139 - acc: 0.9557 - val_loss: 0.1316 - val_acc: 0.9558\n",
      "2048/2060 [============================>.] - ETA: 0s\n",
      " \n",
      " ***************** 7 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6373 - acc: 0.7280 - val_loss: 0.4666 - val_acc: 0.7966\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3935 - acc: 0.8446 - val_loss: 0.3850 - val_acc: 0.8388\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2929 - acc: 0.8889 - val_loss: 0.2930 - val_acc: 0.8883\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2355 - acc: 0.9137 - val_loss: 0.2712 - val_acc: 0.8942\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2046 - acc: 0.9238 - val_loss: 0.2685 - val_acc: 0.8922\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1822 - acc: 0.9339 - val_loss: 0.2268 - val_acc: 0.9218\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1653 - acc: 0.9370 - val_loss: 0.2466 - val_acc: 0.9044\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1534 - acc: 0.9421 - val_loss: 0.1942 - val_acc: 0.9311\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1425 - acc: 0.9476 - val_loss: 0.2163 - val_acc: 0.9150\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1342 - acc: 0.9479 - val_loss: 0.1964 - val_acc: 0.9282\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5567 - acc: 0.7983 - val_loss: 0.3173 - val_acc: 0.8786\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1916 - acc: 0.9323 - val_loss: 0.1518 - val_acc: 0.9408\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1373 - acc: 0.9467 - val_loss: 0.1283 - val_acc: 0.9442\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1212 - acc: 0.9495 - val_loss: 0.1237 - val_acc: 0.9515\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1094 - acc: 0.9559 - val_loss: 0.1162 - val_acc: 0.9573\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1040 - acc: 0.9575 - val_loss: 0.1225 - val_acc: 0.9568\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0987 - acc: 0.9606 - val_loss: 0.1141 - val_acc: 0.9568\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0973 - acc: 0.9625 - val_loss: 0.1188 - val_acc: 0.9510\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0918 - acc: 0.9644 - val_loss: 0.1157 - val_acc: 0.9529\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0897 - acc: 0.9649 - val_loss: 0.1224 - val_acc: 0.9529\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6610 - acc: 0.7440 - val_loss: 0.4205 - val_acc: 0.8510\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3222 - acc: 0.8886 - val_loss: 0.2925 - val_acc: 0.8835\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2213 - acc: 0.9209 - val_loss: 0.1906 - val_acc: 0.9320\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1780 - acc: 0.9323 - val_loss: 0.1828 - val_acc: 0.9408\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1557 - acc: 0.9423 - val_loss: 0.1720 - val_acc: 0.9422\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1411 - acc: 0.9473 - val_loss: 0.1541 - val_acc: 0.9374\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1283 - acc: 0.9523 - val_loss: 0.1378 - val_acc: 0.9539\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1230 - acc: 0.9541 - val_loss: 0.1453 - val_acc: 0.9456\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1154 - acc: 0.9568 - val_loss: 0.1329 - val_acc: 0.9505\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1110 - acc: 0.9563 - val_loss: 0.1321 - val_acc: 0.9500\n",
      "1728/2060 [========================>.....] - ETA: 0s\n",
      " \n",
      " ***************** 8 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6592 - acc: 0.7250 - val_loss: 0.5081 - val_acc: 0.7976\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3862 - acc: 0.8494 - val_loss: 0.3318 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2880 - acc: 0.8908 - val_loss: 0.2784 - val_acc: 0.8995\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2383 - acc: 0.9088 - val_loss: 0.2548 - val_acc: 0.9141\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2076 - acc: 0.9192 - val_loss: 0.2189 - val_acc: 0.9107\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1863 - acc: 0.9278 - val_loss: 0.2151 - val_acc: 0.9150\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1703 - acc: 0.9345 - val_loss: 0.2001 - val_acc: 0.9194\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1598 - acc: 0.9374 - val_loss: 0.1850 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1503 - acc: 0.9397 - val_loss: 0.1844 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1431 - acc: 0.9449 - val_loss: 0.1774 - val_acc: 0.9320\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6051 - acc: 0.7779 - val_loss: 0.3127 - val_acc: 0.8840\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2037 - acc: 0.9297 - val_loss: 0.1664 - val_acc: 0.9461\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1402 - acc: 0.9443 - val_loss: 0.1276 - val_acc: 0.9471\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1236 - acc: 0.9482 - val_loss: 0.1176 - val_acc: 0.9534\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1140 - acc: 0.9525 - val_loss: 0.1218 - val_acc: 0.9563\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1092 - acc: 0.9559 - val_loss: 0.1070 - val_acc: 0.9587\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1041 - acc: 0.9570 - val_loss: 0.1006 - val_acc: 0.9626\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0990 - acc: 0.9592 - val_loss: 0.1345 - val_acc: 0.9490\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.0968 - acc: 0.9598 - val_loss: 0.0978 - val_acc: 0.9680\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0945 - acc: 0.9604 - val_loss: 0.1033 - val_acc: 0.9670\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6619 - acc: 0.7314 - val_loss: 0.4508 - val_acc: 0.8500\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.3416 - acc: 0.8780 - val_loss: 0.2741 - val_acc: 0.9044\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2350 - acc: 0.9154 - val_loss: 0.2148 - val_acc: 0.9160\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1892 - acc: 0.9296 - val_loss: 0.1789 - val_acc: 0.9345\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1659 - acc: 0.9386 - val_loss: 0.1944 - val_acc: 0.9194\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1494 - acc: 0.9399 - val_loss: 0.1502 - val_acc: 0.9422\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1377 - acc: 0.9460 - val_loss: 0.1568 - val_acc: 0.9350\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1289 - acc: 0.9506 - val_loss: 0.1327 - val_acc: 0.9490\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1221 - acc: 0.9502 - val_loss: 0.1312 - val_acc: 0.9481\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1156 - acc: 0.9545 - val_loss: 0.1279 - val_acc: 0.9500\n",
      "1120/2060 [===============>..............] - ETA: 0s\n",
      " \n",
      " ***************** 9 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6446 - acc: 0.7342 - val_loss: 0.4377 - val_acc: 0.8301\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.4123 - acc: 0.8315 - val_loss: 0.3568 - val_acc: 0.8660\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3177 - acc: 0.8808 - val_loss: 0.2750 - val_acc: 0.8942\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2580 - acc: 0.9056 - val_loss: 0.2605 - val_acc: 0.8951\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.2217 - acc: 0.9184 - val_loss: 0.2169 - val_acc: 0.9218\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1988 - acc: 0.9254 - val_loss: 0.2223 - val_acc: 0.9194\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1847 - acc: 0.9298 - val_loss: 0.1929 - val_acc: 0.9330\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1694 - acc: 0.9357 - val_loss: 0.2104 - val_acc: 0.9243\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1588 - acc: 0.9414 - val_loss: 0.1966 - val_acc: 0.9180\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1502 - acc: 0.9440 - val_loss: 0.1901 - val_acc: 0.9199\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.5475 - acc: 0.8119 - val_loss: 0.2387 - val_acc: 0.9218\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1874 - acc: 0.9298 - val_loss: 0.1373 - val_acc: 0.9510\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1387 - acc: 0.9437 - val_loss: 0.1256 - val_acc: 0.9515\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1228 - acc: 0.9511 - val_loss: 0.1009 - val_acc: 0.9655\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1145 - acc: 0.9507 - val_loss: 0.1078 - val_acc: 0.9563\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1102 - acc: 0.9546 - val_loss: 0.1017 - val_acc: 0.9665\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1078 - acc: 0.9556 - val_loss: 0.0937 - val_acc: 0.9665\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1022 - acc: 0.9584 - val_loss: 0.0975 - val_acc: 0.9636\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.0990 - acc: 0.9606 - val_loss: 0.0892 - val_acc: 0.9680\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.0959 - acc: 0.9620 - val_loss: 0.0898 - val_acc: 0.9680\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "Epoch 1/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.6740 - acc: 0.7381 - val_loss: 0.4126 - val_acc: 0.8286\n",
      "Epoch 2/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.3369 - acc: 0.8817 - val_loss: 0.2908 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.2353 - acc: 0.9153 - val_loss: 0.2223 - val_acc: 0.9092\n",
      "Epoch 4/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1919 - acc: 0.9292 - val_loss: 0.1733 - val_acc: 0.9422\n",
      "Epoch 5/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1690 - acc: 0.9369 - val_loss: 0.1650 - val_acc: 0.9359\n",
      "Epoch 6/10\n",
      "8239/8239 [==============================] - 1s - loss: 0.1504 - acc: 0.9444 - val_loss: 0.1725 - val_acc: 0.9403\n",
      "Epoch 7/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1415 - acc: 0.9460 - val_loss: 0.2003 - val_acc: 0.9272\n",
      "Epoch 8/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1308 - acc: 0.9513 - val_loss: 0.1382 - val_acc: 0.9481\n",
      "Epoch 9/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1262 - acc: 0.9527 - val_loss: 0.1322 - val_acc: 0.9471\n",
      "Epoch 10/10\n",
      "8239/8239 [==============================] - 0s - loss: 0.1197 - acc: 0.9557 - val_loss: 0.1342 - val_acc: 0.9432\n",
      "1856/2060 [==========================>...] - ETA: 0s\n",
      " [[ 0.89563107  0.95970874  0.94757282]\n",
      " [ 0.94126214  0.96796117  0.95048544]\n",
      " [ 0.92475728  0.96456311  0.95194175]\n",
      " [ 0.91601942  0.9684466   0.95145631]\n",
      " [ 0.9276699   0.95533981  0.94805825]\n",
      " [ 0.91407767  0.96067961  0.94029126]\n",
      " [ 0.92864078  0.95533981  0.95582524]\n",
      " [ 0.92815534  0.95291262  0.95      ]\n",
      " [ 0.93203884  0.96699029  0.95      ]\n",
      " [ 0.91990291  0.96796117  0.94320388]]\n",
      "[ 92.28155341  96.19902913  94.88834952]\n"
     ]
    }
   ],
   "source": [
    "N_MC=10\n",
    "\n",
    "score=np.empty([N_MC,3])\n",
    "# score est une matrice nb_methodes x B\n",
    "for k in range(N_MC):\n",
    "    print(\"\\n \\n *****************\",k,\"***************** \\n\")\n",
    "    X_train_MC,X_test_MC,Y_train_dummies_MC,Y_test_dummies_MC=train_test_split(X,Y,test_size=0.2)\n",
    "    N_train_MC = X_train_MC.shape[0]\n",
    "    N_test_MC = X_test_MC.shape[0]\n",
    "    \n",
    "    timesteps = len(X_train_MC[0])\n",
    "    input_dim = len(X_train_MC[0][0])\n",
    "    \n",
    "    X_train_conv_MC = X_train_MC.reshape(N_train_MC, timesteps, input_dim, 1)\n",
    "    X_test_conv_MC = X_test_MC.reshape(N_test_MC, timesteps, input_dim, 1)\n",
    "    \n",
    "    # définition des modèles \n",
    "    model_base_mlp =km.Sequential()\n",
    "    model_base_mlp.add(kl.Dense(n_hidden, input_shape=(timesteps, input_dim),  activation = \"relu\"))\n",
    "    model_base_mlp.add(kl.Reshape((timesteps*n_hidden,) , input_shape= (timesteps, n_hidden)  ))\n",
    "    model_base_mlp.add(kl.Dense(n_classes, activation='softmax'))\n",
    "    model_base_mlp.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    model_base_conv_1D =km.Sequential()\n",
    "    model_base_conv_1D.add(kl.Conv1D(32, 9, activation='relu', input_shape=(timesteps, input_dim)))\n",
    "    model_base_conv_1D.add(kl.MaxPooling1D(pool_size=3))\n",
    "    model_base_conv_1D.add(kl.Flatten())\n",
    "    model_base_conv_1D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "    model_base_conv_1D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    model_base_conv_2D =km.Sequential()\n",
    "    model_base_conv_2D.add(kl.Conv2D(32, (3, 9), activation='relu', input_shape=(timesteps, input_dim, 1)))\n",
    "    model_base_conv_2D.add(kl.MaxPooling2D(pool_size=(2, 1)))\n",
    "    model_base_conv_2D.add(kl.Flatten())\n",
    "    model_base_conv_2D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "    model_base_conv_2D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"\\n **** MLP **** \\n\")\n",
    "    model_base_mlp.fit(X_train_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_MC, Y_test_dummies_MC), epochs=epochs)   \n",
    "    #print(\"\\n **** LSTM **** \\n\")\n",
    "    #model_base_lstm.fit(X_train_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_MC, Y_test_dummies_MC), epochs=epochs, shuffle=False)\n",
    "    print(\"\\n **** conv 1D **** \\n\")\n",
    "    model_base_conv_1D.fit(X_train_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_MC, Y_test_dummies_MC), epochs=epochs)\n",
    "    print(\"\\n **** conv 2D **** \\n\")\n",
    "    model_base_conv_2D.fit(X_train_conv_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_conv_MC, Y_test_dummies_MC), epochs=epochs)\n",
    "    \n",
    "    score_mlp=model_base_mlp.evaluate(X_test_MC, Y_test_dummies_MC)[1]\n",
    "    #score_lstm=model_base_lstm.evaluate(X_test_MC, Y_test_dummies_MC)[1]\n",
    "    score_conv_1D=model_base_conv_1D.evaluate(X_test_MC, Y_test_dummies_MC)[1]\n",
    "    score_conv_2D=model_base_conv_2D.evaluate(X_test_conv_MC, Y_test_dummies_MC)[1]\n",
    "    s=[score_mlp,score_conv_1D,score_conv_2D]\n",
    "    score[k,:]=s\n",
    "    \n",
    "final_scores=np.apply_along_axis(np.mean,0,score)*100\n",
    "print(\"\\n\",score)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP     : 92.28 % \n",
      "\n",
      "Conv 1D : 96.2 % \n",
      "\n",
      "Conv 2D : 94.89 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP     :\",round(final_scores[0],2),\"% \\n\")\n",
    "print(\"Conv 1D :\",round(final_scores[1],2),\"% \\n\")\n",
    "print(\"Conv 2D :\",round(final_scores[2],2),\"% \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour trois modèles de réseaux de neurones (`model_base_mlp`, `model_base_conv_1D` et `model_base_conv_2D`), nous avons effectué la validation croisée de Monte Carlo en divisant k=10 fois successivement l'échantillon complet en train et test. Nous avons moyenné les erreurs obtenues sur l'échantillon test pour avoir une meilleure idée (moins optimiste) de la performance de chaque méthode. \n",
    "\n",
    "Nous pouvons voir par exemple ici, que le réseau de neurone convolutionnel 1D obtient de meilleurs résultats en moyenne. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
