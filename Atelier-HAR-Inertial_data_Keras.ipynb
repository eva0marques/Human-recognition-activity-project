{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance d'Activité Humaine](https://github.com/wikistat/Ateliers-Big-Data/5-HumanActivityRecognition) ([*HAR*](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>  \n",
    "##  Seconde partie:  apprentissage (profond) des signaux bruts  avec <a href=\"https://keras.io/\"><img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" style=\"max-width: 100px; display: inline\" alt=\"Keras\"/></a>\n",
    "\n",
    "Ce notebook présente la partie prediction de l'activité. Pour l'exploration, se référer au calepin afférent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Introduction\n",
    "###  1.1 Contexte\n",
    "Les données sont issues de la communauté qui vise la reconnaissance d'activités humaines (*Human activity recognition, HAR*) à partir d’enregistrements, par exemple du gyroscope et de l'accéléromètre d'un smartphone.\n",
    "Voir à ce propos l'[article](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) relatant un colloque de 2013.  \n",
    "\n",
    "Les données publiques disponibles ont été acquises, décrites et analysées par [Anguita et al. (2013)](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf). Elles sont accessibles sur le [dépôt](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) de l'University California Irvine (UCI) consacré à l'apprentissage machine ainsi que sur le site *Kaggle*.\n",
    "\n",
    "L'archive contient les données brutes: accélérations en x, y, et z, chacun de 128 colonnes. D'autres fichiers en y soustrayant la gravité naturelle ainsi que les accélérations angulaires en x, y, et z, soit en tout 9 fichiers. Mais 6 utiles avec 6*128=768 mesures.\n",
    "\n",
    "Les méthodes d'apprentissage sont appliquées sur ces données brutes, sans calculs préliminaires de caractéristiques (*features*).\n",
    "\n",
    "### 1.2 Objectif\n",
    "Cette deuxième étape s'intéresse aux données brutes. Est-il possible d'économiser le travail préliminaire de définition des variables métier en utilisant, par exemple, les ressources de décompositions systématiques sur une base d'ondelette ou un algorihtme d'apprentissage profond?\n",
    "\n",
    "**Objecctif** Faire aussi bien (96% de bien classés) qu'avec les variables métier.\n",
    "\n",
    "### 1.3 Travail à réaliser\n",
    "**Attention l'accès à un environnement *GPU* est très vivement conseillé voire indispensable.**\n",
    "- Modélisation, prévision de l'échantillon test par\n",
    "   - Régression logistique (`Scikit-learn`)\n",
    "   - Apprentissage profond en utilisant `Keras` \n",
    "       - MLP sur signaux \"applatis\"\n",
    "       - MLP sur signaux mutlidimensionelles\n",
    "       - LSTM\n",
    "       - 1D Convolution\n",
    "       - 2D Convolution\n",
    "   \n",
    "- Ajouter à ce calepin: \n",
    "    - Application des méthodes d'apprentissage classique ou non sur les coefficients des décompositions des signaux en ondelettes\n",
    "    - optimisation des paramètres des différentes méthodes.\n",
    "    - Améliorer l'architexture des réseaux?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Mise en place\n",
    "### 2.1 Librairies et initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\IPython\\kernel\\__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated since IPython 4.0.You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named seaborn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47b22fea5183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib notebook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named seaborn"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#Utils Sklearn\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "\n",
    "# DEEP LEARING\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "# for reproducibility\n",
    "# https://github.com/fchollet/keras/issues/2280\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras.models as km \n",
    "import keras.layers as kl \n",
    "import keras.layers.core as klc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### 2.2 Prise en charge des données\n",
    "#### Sources\n",
    "\n",
    "Les données sont celles originales du dépôt de l'[UCI](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Elle peuvent être téléchargées en cliquant [ici](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip).\n",
    "\n",
    "Elles contiennent deux jeux de dimensions différentes, chacun partagé en apprentissage et test.\n",
    "\n",
    "1. Multidimensionel: un individus est constitué de 9 Séries Temporelles de *dimensions* $(N, 128, 9)$\n",
    "2. Unidimensionnel: Les 9 Séries Temporelles sont concaténées pour constituer un vecteur de 128*9 = 1152 variables de *dimensions* $(N, 1152)*\n",
    "        \n",
    "Deux objets différents sont construits pour définir la variable $Y$ réponse car les librairies `Scikit-learn` et `Keras` prennent en compte des structures différentes: \n",
    "    \n",
    "1. `Scikit-Learn`  Un vecteur de dimension $(N, 1)$ avec, pour chaque individu le numéro du label de l'activité de 0 à 5.\n",
    "2. `Keras` Une matrice de dimension $(N, 6)$ des indicatrices (0 ou 1) des modalités de $Y$.\n",
    "\n",
    "#### Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-4df3c6bad598>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-4df3c6bad598>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    filename = f'{data_dir}/{subset}/Inertial Signals/{signal}_{subset}.txt'\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "DATADIR_UCI = '~/DeepLearning/data/HARWS//UCI HAR Dataset'\n",
    "\n",
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\", \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]\n",
    "\n",
    "def my_read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "def load_signal(data_dir, subset, signal):\n",
    "    filename = f'{data_dir}/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "    x = my_read_csv(filename).as_matrix()\n",
    "    return x \n",
    "\n",
    "def load_signals(data_dir, subset, flatten = False):\n",
    "    signals_data = []\n",
    "    for signal in SIGNALS:\n",
    "        signals_data.append(load_signal(data_dir, subset, signal)) \n",
    "    \n",
    "    if flatten :\n",
    "        X = np.hstack(signals_data)\n",
    "    else:\n",
    "        X = np.transpose(signals_data, (1, 2, 0))\n",
    "        \n",
    "    return X \n",
    "\n",
    "def load_y(data_dir, subset, dummies = False):\n",
    "    filename = f'{data_dir}/{subset}/y_{subset}.txt'\n",
    "    y = my_read_csv(filename)[0]\n",
    "    \n",
    "    \n",
    "    if dummies:\n",
    "        Y = pd.get_dummies(y).as_matrix()\n",
    "    else:\n",
    "        Y = y.as_matrix()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_signals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e69d927ddef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Multidimensional Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATADIR_UCI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATADIR_UCI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Flattened Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_flatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_flatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATADIR_UCI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATADIR_UCI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_signals' is not defined"
     ]
    }
   ],
   "source": [
    "#Multidimensional Data\n",
    "X_train, X_test = load_signals(DATADIR_UCI, 'train'), load_signals(DATADIR_UCI, 'test')\n",
    "# Flattened Data\n",
    "X_train_flatten, X_test_flatten = load_signals(DATADIR_UCI, 'train', flatten=True), load_signals(DATADIR_UCI, 'test', flatten=True)\n",
    "\n",
    "# Label Y\n",
    "Y_train_label, Y_test_label = load_y(DATADIR_UCI, 'train', dummies = False), load_y(DATADIR_UCI, 'test', dummies = False)\n",
    "#Dummies Y (For Keras)\n",
    "Y_train_dummies, Y_test_dummies = load_y(DATADIR_UCI, 'train', dummies = True), load_y(DATADIR_UCI, 'test', dummies = True)\n",
    "\n",
    "N_train = X_train.shape[0]\n",
    "N_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension\n",
      "Données Multidimensionelles, : (7352, 128, 9)\n",
      "Données Unimensionelles, : (7352, 1152)\n",
      "Vecteur réponse (scikit-learn) : (7352,)\n",
      "Matrice réponse(Keras) : (7352, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension\")\n",
    "print(\"Données Multidimensionelles, : \" + str(X_train.shape))\n",
    "print(\"Données Unimensionelles, : \" + str(X_train_flatten.shape))\n",
    "print(\"Vecteur réponse (scikit-learn) : \" + str(Y_train_label.shape))\n",
    "print(\"Matrice réponse(Keras) : \" + str(Y_train_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/bguillouet/Insa/DeepLearning/data/HARWS/\"\n",
    "LABELS = [\"WALKING\",\"WALKING UPSTAIRS\",\"WALKING DOWNSTAIRS\",\"SITTING\",\"STANDING\",\"LAYING\"]\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "\n",
    "def my_confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Apprentissage des signaux uni-dimensionels\n",
    "\n",
    "La base d'apprentissage est de dimension (`N_train`, 1152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Régression Logistique\n",
    "\n",
    "La Régression Logistique est une des méthodes conduisant aux meilleurs résultats sur les vairables métier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Score With Logistic Regression on Inertial Signals = 57.45, Learning time = 33.21 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>120</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>74</td>\n",
       "      <td>218</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>93</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>397</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>129</td>\n",
       "      <td>92</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 120                63                  97        0   \n",
       "WALKING UPSTAIRS         74               218                  56       23   \n",
       "WALKING DOWNSTAIRS       93                66                 103        1   \n",
       "SITTING                  80                32                  58      397   \n",
       "STANDING                129                92                 106       70   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    1       0  \n",
       "WALKING UPSTAIRS          72      27  \n",
       "WALKING DOWNSTAIRS         2       0  \n",
       "SITTING                  112       0  \n",
       "STANDING                 345       0  \n",
       "LAYING                     0     510  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_lr = lm.LogisticRegression(verbose=1)\n",
    "model_lr.fit(X_train_flatten, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lr.score(X_test_flatten, Y_test_label)\n",
    "print(\"Score With Logistic Regression on Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lr_prediction_label = model_lr.predict(X_test_flatten)\n",
    "metadata_svc = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lr_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de la performance?\n",
    "\n",
    "**TODO?** Tester d'autre méthode (SVM, XGBOOST?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Perceptron multicouche\n",
    "\n",
    "Un réseau de neurones classique est appris sur les données au même format que précédemment.\n",
    "\n",
    "**Q** Expliciter les choix des paramètres et donc la structure du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,094\n",
      "Trainable params: 37,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_hidden = 32\n",
    "\n",
    "n_features = X_train_flatten.shape[1]\n",
    "n_classes=6\n",
    "\n",
    "\n",
    "model_base_mlp_u =km.Sequential()\n",
    "model_base_mlp_u.add(kl.Dense(n_hidden, input_shape=(n_features,),  activation = \"relu\"))\n",
    "model_base_mlp_u.add(kl.Dropout(0.5))\n",
    "model_base_mlp_u.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_mlp_u.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model_base_mlp_u.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 2s - loss: 1.0896 - acc: 0.5718 - val_loss: 0.8785 - val_acc: 0.7530\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.8247 - acc: 0.6882 - val_loss: 0.7398 - val_acc: 0.7876\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.7230 - acc: 0.7339 - val_loss: 0.6610 - val_acc: 0.8124\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.6697 - acc: 0.7538 - val_loss: 0.6543 - val_acc: 0.8198\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.6294 - acc: 0.7674 - val_loss: 0.6185 - val_acc: 0.8239\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.5986 - acc: 0.7792 - val_loss: 0.5699 - val_acc: 0.8378\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.5769 - acc: 0.7855 - val_loss: 0.6064 - val_acc: 0.8256\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.5615 - acc: 0.7901 - val_loss: 0.5529 - val_acc: 0.8422\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.5595 - acc: 0.7888 - val_loss: 0.5459 - val_acc: 0.8320\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.5380 - acc: 0.7962 - val_loss: 0.5523 - val_acc: 0.8293\n",
      "1568/2947 [==============>...............] - ETA: 0sScore With Simple MLP on Inertial Signals = 82.93, Learning time = 7.90 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>418</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>361</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 520        0         0        0                   0   \n",
       "SITTING                  0      346       140        2                   0   \n",
       "STANDING                 0       83       439        0                   3   \n",
       "WALKING                  0       12         1      418                  54   \n",
       "WALKING_DOWNSTAIRS       0        3         1       33                 361   \n",
       "WALKING_UPSTAIRS         0        3         0       47                  61   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            17  \n",
       "SITTING                            3  \n",
       "STANDING                           7  \n",
       "WALKING                           11  \n",
       "WALKING_DOWNSTAIRS                22  \n",
       "WALKING_UPSTAIRS                 360  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp_u.fit(X_train_flatten,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test_flatten, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp_u.evaluate(X_test_flatten, Y_test_dummies)[1] \n",
    "print(\"Score With Simple MLP on Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp_u = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_u_prediction = model_base_mlp_u.predict(X_test_flatten)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_u_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q ** : Que conclure sur ces résultats en terme de performance, de temps d'apprentissage? Comparer avec la regression logistique?\n",
    "\n",
    "** Exo ** : Quel est l'influence de l'ajout de nouvelle couche? Supression du Dropout? ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Réseau avec couche convolutionelle (*ConvNet*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 2s - loss: 0.5387 - acc: 0.8001 - val_loss: 0.6148 - val_acc: 0.7306\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.2015 - acc: 0.9289 - val_loss: 0.3446 - val_acc: 0.8795\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1473 - acc: 0.9446 - val_loss: 0.2988 - val_acc: 0.8951\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1356 - acc: 0.9445 - val_loss: 0.2744 - val_acc: 0.9023\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1263 - acc: 0.9453 - val_loss: 0.3197 - val_acc: 0.9050\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1245 - acc: 0.9502 - val_loss: 0.3189 - val_acc: 0.9162\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1261 - acc: 0.9455 - val_loss: 0.3360 - val_acc: 0.9084\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1334 - acc: 0.9429 - val_loss: 0.3699 - val_acc: 0.9165\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1356 - acc: 0.9482 - val_loss: 0.4902 - val_acc: 0.8945\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 1s - loss: 0.1434 - acc: 0.9479 - val_loss: 0.4360 - val_acc: 0.9145\n",
      "2592/2947 [=========================>....] - ETA: 0sScore With Conv on Multidimensional Inertial Signals = 91.45, Learning time = 18.74 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>341</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      341       142        0                   0   \n",
       "STANDING                 0       37       493        1                   0   \n",
       "WALKING                  0        0         0      486                   7   \n",
       "WALKING_DOWNSTAIRS       0        0         0        2                 416   \n",
       "WALKING_UPSTAIRS         0        0         0        5                  17   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                            8  \n",
       "STANDING                           1  \n",
       "WALKING                            3  \n",
       "WALKING_DOWNSTAIRS                 2  \n",
       "WALKING_UPSTAIRS                 449  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "#else:\n",
    "model_base_conv_1D =km.Sequential()\n",
    "model_base_conv_1D.add(kl.Conv1D(32, 9, activation='relu', input_shape=(timesteps, input_dim)))\n",
    "model_base_conv_1D.add(kl.MaxPooling1D(pool_size=3))\n",
    "model_base_conv_1D.add(kl.Flatten())\n",
    "model_base_conv_1D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_1D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "t_start = time.time()\n",
    "model_base_conv_1D.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_1D.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"Score With Conv on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_1D_prediction = model_base_conv_1D.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_conv_1D_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_base_conv_1D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Apprentissage des signaux multidimensionnels\n",
    "Les différents signaux ne sont pas concaténées en un seul signal mais pris en compte parallèlement.\n",
    "\n",
    "### 4.1 Perceptron multichouche\n",
    "**Q** Expliciter les choix des paramètres et donc la structure du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.6266 - acc: 0.7414 - val_loss: 0.7181 - val_acc: 0.7302\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.4158 - acc: 0.8301 - val_loss: 0.6631 - val_acc: 0.7917\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.3455 - acc: 0.8641 - val_loss: 0.6318 - val_acc: 0.8188\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2961 - acc: 0.8852 - val_loss: 0.6573 - val_acc: 0.8222\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2710 - acc: 0.8930 - val_loss: 0.6858 - val_acc: 0.8168\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2439 - acc: 0.9100 - val_loss: 0.6604 - val_acc: 0.8286\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2389 - acc: 0.9060 - val_loss: 0.8035 - val_acc: 0.8018\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2223 - acc: 0.9123 - val_loss: 0.8537 - val_acc: 0.7835\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2202 - acc: 0.9149 - val_loss: 0.6438 - val_acc: 0.8537\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s - loss: 0.2122 - acc: 0.9203 - val_loss: 0.7617 - val_acc: 0.8079\n",
      "2400/2947 [=======================>......] - ETA: 0sScore With Simple MLP on Multidimensional Inertial Signals = 80.79, Learning time = 7.89 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>406</td>\n",
       "      <td>68</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>355</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      452        14        1                   0   \n",
       "STANDING                 0      273       250        2                   0   \n",
       "WALKING                  0        5         0      406                  68   \n",
       "WALKING_DOWNSTAIRS       0        9         0       42                 355   \n",
       "WALKING_UPSTAIRS         0        0         0       46                  17   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                           24  \n",
       "STANDING                           7  \n",
       "WALKING                           17  \n",
       "WALKING_DOWNSTAIRS                14  \n",
       "WALKING_UPSTAIRS                 408  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 32\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "model_base_mlp =km.Sequential()\n",
    "model_base_mlp.add(kl.Dense(n_hidden, input_shape=(timesteps, input_dim),  activation = \"relu\"))\n",
    "model_base_mlp.add(kl.Reshape((timesteps*n_hidden,) , input_shape= (timesteps, n_hidden)  ))\n",
    "model_base_mlp.add(kl.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_base_mlp.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "t_start = time.time()\n",
    "model_base_mlp.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"Score With Simple MLP on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_prediction = model_base_mlp.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128, 32)           320       \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 24,902\n",
      "Trainable params: 24,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 *Long Short Time Memory (LSTM)*\n",
    "Test d'un réseau avec couche LSTM avec l'idée d'appréhender la structure temporelle des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hide_input": true
   },
   "source": [
    "#### *Statelesss Mode*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 32\n",
    "#default stateful = False\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "batch_size=64\n",
    "#else:\n",
    "model_base_lstm =km.Sequential()\n",
    "model_base_lstm.add(kl.LSTM(n_hidden, input_shape=(timesteps, input_dim), stateful=False))\n",
    "model_base_lstm.add(kl.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_base_lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model_base_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 22s - loss: 1.4789 - acc: 0.3935 - val_loss: 1.2950 - val_acc: 0.4880\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 20s - loss: 1.1747 - acc: 0.5057 - val_loss: 1.2254 - val_acc: 0.5120\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 21s - loss: 1.1418 - acc: 0.5031 - val_loss: 1.1692 - val_acc: 0.5389\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 21s - loss: 1.0597 - acc: 0.5605 - val_loss: 1.0674 - val_acc: 0.5467\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 21s - loss: 0.9046 - acc: 0.6457 - val_loss: 0.9655 - val_acc: 0.5959\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 21s - loss: 0.8009 - acc: 0.6613 - val_loss: 0.9069 - val_acc: 0.6312\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 20s - loss: 0.7589 - acc: 0.6742 - val_loss: 0.8364 - val_acc: 0.6780\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 20s - loss: 0.7063 - acc: 0.7074 - val_loss: 0.7793 - val_acc: 0.7065\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 21s - loss: 0.6842 - acc: 0.7451 - val_loss: 0.7654 - val_acc: 0.7078\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 21s - loss: 0.6399 - acc: 0.7656 - val_loss: 0.7693 - val_acc: 0.7197\n",
      "2944/2947 [============================>.] - ETA: 0sScore With Simple MLP on Multidimensional Inertial Signals = 71.97, Learning time = 213.56 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>118</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>417</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>45</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>208</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>77</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      345       118       23                   3   \n",
       "STANDING                 0       45       417       60                   3   \n",
       "WALKING                  0        0         1      297                  45   \n",
       "WALKING_DOWNSTAIRS       0        0         0       50                 208   \n",
       "WALKING_UPSTAIRS         0        0         1       49                  77   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                            2  \n",
       "STANDING                           7  \n",
       "WALKING                          153  \n",
       "WALKING_DOWNSTAIRS               162  \n",
       "WALKING_UPSTAIRS                 344  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default shuffle = True Meilleur avec Shuffle m True\n",
    "t_start = time.time()\n",
    "model_base_lstm.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs, shuffle=False)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_lstm.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"Score With Simple MLP on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_lstm = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_lstm_prediction = model_base_lstm.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_lstm_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### *Statefull Mode*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2944/2947 [============================>.] - ETA: 0s[0.49561213459482323, 0.92093654563963356]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_path = DATA_DIR+\"keras_model/LSTM_dense.h5\"\n",
    "if os.path.isfile(model_path):\n",
    "    model_base_lstm_92 = km.load_model(model_path)\n",
    "    print(model_base_lstm_92.evaluate(X_test,Y_test_dummies))\n",
    "    print(model_base_lstm_92.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Réseau avec couche convolutionelle (*ConvNet*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f0c914e1bf7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtimesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "X_train_conv = X_train.reshape(N_train, timesteps, input_dim, 1)\n",
    "X_test_conv = X_test.reshape(N_test, timesteps, input_dim, 1)\n",
    "\n",
    "#else:\n",
    "model_base_conv_2D =km.Sequential()\n",
    "model_base_conv_2D.add(kl.Conv2D(32, (3, 9), activation='relu', input_shape=(timesteps, input_dim, 1)))\n",
    "model_base_conv_2D.add(kl.MaxPooling2D(pool_size=(2, 1)))\n",
    "model_base_conv_2D.add(kl.Flatten())\n",
    "model_base_conv_2D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_2D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "t_start = time.time()\n",
    "model_base_conv_2D.fit(X_train_conv,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test_conv, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_2D.evaluate(X_test_conv, Y_test_dummies)[1] \n",
    "print(\"Score With Conv on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_2D_prediction = model_base_conv_2D.predict(X_test_conv)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_conv_2D_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 1, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 12102     \n",
      "=================================================================\n",
      "Total params: 12,998\n",
      "Trainable params: 12,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base_conv_2D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Objectif** trouver la meilleure architecture.\n",
    "\n",
    "**Attention au sur-apprentissage** A force de rechercher la meilleure architecture en minimisant l'erreur sur l'échantillon test, celle finalement trouvée peut y être très adaptée réduisant ainsi la capacité de généralisation. Il serait prudent de multiplier le découpage de l'échantillon par validation croisée *Monte Carlo*."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
